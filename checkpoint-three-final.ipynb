{
    "cells": [
        {
            "attachments": {},
            "cell_type": "markdown",
            "metadata": {
                "azdata_cell_guid": "26037d32-2047-4157-81ef-595916bd66a0"
            },
            "source": [
                "# Checkpoint Three: Cleaning Data:  I DID THIS BEFORE CHECKPOINT 2!\n",
                "\n",
                "Now you are ready to clean your data. Before starting coding, provide the link to your dataset below.\n",
                "\n",
                "My dataset: https://nces.ed.gov/ipeds/use-the-data#SurveyData\n",
                "\n",
                "Import the necessary libraries and create your dataframe(s)."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 19,
            "metadata": {
                "azdata_cell_guid": "e8adef8e-d0f2-4640-a179-5997f11e82ca"
            },
            "outputs": [],
            "source": [
                "# First import necessary libraries\n",
                "import pandas as pd\n",
                "import numpy as np\n",
                "\n",
                "# Next import data. Note that these files were chosen from the Institute of Education Sciences from US-DOE's \"Integrated Postsecondary Education Data Systems\". \n",
                "# “IPEDS is a system of 12 interrelated survey components conducted annually that gathers data from every college, university, and technical and vocational \n",
                "# institution that participates in the federal student financial aid programs. The data collections occur in fall, winter, and spring” (nces.ed.gov/ipeds).\n",
                "# The datasets chosen were those that contained INSTITUTIONAL data from the most recent year (2024) back through 1996, thus constituting 29 years' worth of data.\n",
                "# More specifically, I chose the data from this website: https://nces.ed.gov/ipeds/use-the-data#SurveyData, under COMPLETE DATA FILES, then filtered by \"Completions\",\n",
                "# and finally choosing \"Awards/degrees conferred by program (6-digit CIP code), award level, race/ethnicity, and gender\" (note that a few of the oldest datasets\n",
                "# only provided 2-digit CIP code, but this was a sufficient level of detail for my purposes). Also note that although I could have used years prior to 1996 in my\n",
                "# analyses, datasets prior to that date did not include race/ethnicity data, which were of interest in this project and/or did not impute missing values, so I chose\n",
                "# to exclude those.\n",
                "\n",
                "year1996 = pd.read_csv(r'C:\\Users\\B\\LCClass\\finalproject\\Original CSVs\\c1996_a.csv')\n",
                "year1997 = pd.read_csv(r'C:\\Users\\B\\LCClass\\finalproject\\Original CSVs\\c1997_a.csv')\n",
                "year1998 = pd.read_csv(r'C:\\Users\\B\\LCClass\\finalproject\\Original CSVs\\c1998_a.csv')\n",
                "year1999 = pd.read_csv(r'C:\\Users\\B\\LCClass\\finalproject\\Original CSVs\\c1999_a.csv')\n",
                "year2000 = pd.read_csv(r'C:\\Users\\B\\LCClass\\finalproject\\Original CSVs\\c2000_a.csv')\n",
                "year2001 = pd.read_csv(r'C:\\Users\\B\\LCClass\\finalproject\\Original CSVs\\c2001_a.csv')\n",
                "year2002 = pd.read_csv(r'C:\\Users\\B\\LCClass\\finalproject\\Original CSVs\\c2002_a.csv')\n",
                "year2003 = pd.read_csv(r'C:\\Users\\B\\LCClass\\finalproject\\Original CSVs\\c2003_a.csv')\n",
                "year2004 = pd.read_csv(r'C:\\Users\\B\\LCClass\\finalproject\\Original CSVs\\c2004_a.csv')\n",
                "year2005 = pd.read_csv(r'C:\\Users\\B\\LCClass\\finalproject\\Original CSVs\\c2005_a.csv')\n",
                "year2006 = pd.read_csv(r'C:\\Users\\B\\LCClass\\finalproject\\Original CSVs\\c2006_a.csv')\n",
                "year2007 = pd.read_csv(r'C:\\Users\\B\\LCClass\\finalproject\\Original CSVs\\c2007_a.csv')\n",
                "year2008 = pd.read_csv(r'C:\\Users\\B\\LCClass\\finalproject\\Original CSVs\\c2008_a.csv')\n",
                "year2009 = pd.read_csv(r'C:\\Users\\B\\LCClass\\finalproject\\Original CSVs\\c2009_a.csv')\n",
                "year2010 = pd.read_csv(r'C:\\Users\\B\\LCClass\\finalproject\\Original CSVs\\c2010_a.csv')\n",
                "year2011 = pd.read_csv(r'C:\\Users\\B\\LCClass\\finalproject\\Original CSVs\\c2011_a.csv')\n",
                "year2012 = pd.read_csv(r'C:\\Users\\B\\LCClass\\finalproject\\Original CSVs\\c2012_a.csv')\n",
                "year2013 = pd.read_csv(r'C:\\Users\\B\\LCClass\\finalproject\\Original CSVs\\c2013_a.csv')\n",
                "year2014 = pd.read_csv(r'C:\\Users\\B\\LCClass\\finalproject\\Original CSVs\\c2014_a.csv')\n",
                "year2015 = pd.read_csv(r'C:\\Users\\B\\LCClass\\finalproject\\Original CSVs\\c2015_a.csv')\n",
                "year2016 = pd.read_csv(r'C:\\Users\\B\\LCClass\\finalproject\\Original CSVs\\c2016_a.csv')\n",
                "year2017 = pd.read_csv(r'C:\\Users\\B\\LCClass\\finalproject\\Original CSVs\\c2017_a.csv')\n",
                "year2018 = pd.read_csv(r'C:\\Users\\B\\LCClass\\finalproject\\Original CSVs\\c2018_a.csv')\n",
                "year2019 = pd.read_csv(r'C:\\Users\\B\\LCClass\\finalproject\\Original CSVs\\c2019_a.csv')\n",
                "year2020 = pd.read_csv(r'C:\\Users\\B\\LCClass\\finalproject\\Original CSVs\\c2020_a.csv')\n",
                "year2021 = pd.read_csv(r'C:\\Users\\B\\LCClass\\finalproject\\Original CSVs\\c2021_a.csv')\n",
                "year2022 = pd.read_csv(r'C:\\Users\\B\\LCClass\\finalproject\\Original CSVs\\c2022_a.csv')\n",
                "year2023 = pd.read_csv(r'C:\\Users\\B\\LCClass\\finalproject\\Original CSVs\\c2023_a.csv')\n",
                "year2024 = pd.read_csv(r'C:\\Users\\B\\LCClass\\finalproject\\Original CSVs\\c2024_a.csv')\n",
                "\n",
                "\n",
                "# NOTE THAT THESE ARE THE VARIABLE NAMES FOR RECENT (2011-2024) DATASETS:\n",
                "#  UNITID\tUnique identification number of the institution\n",
                "#  CIPCODE\tCIP Code -  2020 Classification\n",
                "#  AWLEVEL\tAward Level code\n",
                "#  CTOTALT\tGrand total\n",
                "#  CTOTALM\tGrand total men\n",
                "#  CTOTALW\tGrand total women\n",
                "#  CAIANT\tAmerican Indian or Alaska Native total \n",
                "#  CAIANM\tAmerican Indian or Alaska Native men \n",
                "#  CAIANW\tAmerican Indian or Alaska Native women \n",
                "#  CASIAT\tAsian total \n",
                "#  CASIAM\tAsian men\n",
                "#  CASIAW\tAsian women \n",
                "#  CBKAAT\tBlack or African American total \n",
                "#  CBKAAM\tBlack or African American men \n",
                "#  CBKAAW\tBlack or African American women \n",
                "#  CHISPT\tHispanic or Latino total \n",
                "#  CHISPM\tHispanic or Latino men \n",
                "#  CHISPW\tHispanic or Latino women \n",
                "#  CNHPIT\tNative Hawaiian or Other Pacific Islander total (includes Asian until 2011)\n",
                "#  CNHPIM\tNative Hawaiian or Other Pacific Islander men(includes Asian until 2011)\n",
                "#  CNHPIW\tNative Hawaiian or Other Pacific Islander women (includes Asian until 2011)\n",
                "#  CWHITT\tWhite total \n",
                "#  CWHITM\tWhite men \n",
                "#  CWHITW\tWhite women \n",
                "#  CNRALT\tU.S. Nonresident total\n",
                "#  CNRALM\tU.S. Nonresident men\n",
                "#  CNRALW\tU.S. Nonresident women\n",
                "\n",
                "#AND NOTE THAT FROM 1996-2010, SOME OF THE VARIABLES HAVE DIFFERENT NAMES. WILL NEED TO BE CONVERTED BELOW."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 20,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "(307707, 64)\n",
                        "(303292, 64)\n",
                        "(300877, 64)\n",
                        "(296343, 64)\n",
                        "(289792, 64)\n",
                        "(291052, 64)\n",
                        "(290119, 64)\n",
                        "(308943, 64)\n",
                        "(301984, 64)\n",
                        "(300222, 64)\n",
                        "(293259, 64)\n",
                        "(284907, 64)\n",
                        "(270166, 65)\n",
                        "(265808, 64)\n",
                        "(265604, 124)\n",
                        "(255884, 124)\n",
                        "(247075, 124)\n",
                        "(240507, 52)\n",
                        "(238406, 52)\n",
                        "(230135, 52)\n",
                        "(219682, 52)\n",
                        "(211859, 52)\n",
                        "(200336, 52)\n",
                        "(194569, 36)\n",
                        "(173137, 35)\n",
                        "(153166, 51)\n",
                        "(201825, 37)\n",
                        "(159007, 38)\n",
                        "(158885, 38)\n"
                    ]
                }
            ],
            "source": [
                "#Checking to see how many rows and columns were in each dataframe before beginning any cleaning and manipulation:\n",
                "print(year2024.shape)\n",
                "print(year2023.shape)\n",
                "print(year2022.shape)\n",
                "print(year2021.shape)\n",
                "print(year2020.shape)\n",
                "print(year2019.shape)\n",
                "print(year2018.shape)\n",
                "print(year2017.shape)                      \n",
                "print(year2016.shape)\n",
                "print(year2015.shape)\n",
                "print(year2014.shape)\n",
                "print(year2013.shape)\n",
                "print(year2012.shape)                      \n",
                "print(year2011.shape)\n",
                "print(year2010.shape)\n",
                "print(year2009.shape)\n",
                "print(year2008.shape)\n",
                "print(year2007.shape)                      \n",
                "print(year2006.shape)\n",
                "print(year2005.shape)\n",
                "print(year2004.shape)\n",
                "print(year2003.shape)  \n",
                "print(year2002.shape)\n",
                "print(year2001.shape)\n",
                "print(year2000.shape)\n",
                "print(year1999.shape)\n",
                "print(year1998.shape)\n",
                "print(year1997.shape) \n",
                "print(year1996.shape)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Part 1:  Strip Column Names and make them all UPPER CASE\n",
                "\n",
                "These datasets should be fairly clean, but I did want to make sure the column names didn't contain leading or trailing spaces anywhere, and that they were consistent, capitalization-wise, because I'm going to be using them to match and combine datasets."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 21,
            "metadata": {},
            "outputs": [],
            "source": [
                "#BIG NOTE:  I tried repeatedly to use loops to modify ALL of the dataframes at once. They would seem like they worked, but when I called the dataframes again later, they had not been modified. So I ultimately\n",
                "#went back and removed all of these types of loops from this assignment to ensure I was working with the correctly updated dataframe at all times. As an example of one of the many loops that did not work, just\n",
                "#to illustrate that I tried to use the loops correctly, here's an example of what I used in one of the steps below BEFORE realizing it wasn't changing my dataframes permanently:\n",
                "\n",
                "#EXAMPLE 1\n",
                "#df_w_majornum = [year2011, year2012, year2013, year2014, year2015, year2016, year2017, year2018, year2019, year2020, year2021, year2022, year2023, year2024]\n",
                "#for year in df_w_majornum:\n",
                "#    year = year[(year[\"MAJORNUM\"] == 1)]\n",
                "#    year.shape[0]\n",
                "#    print(year[\"MAJORNUM\"].value_counts())\n",
                "\n",
                "\n",
                "#EXAMPLE 2\n",
                "#all_datasets = [year1996, year1997, year1998, year1999, year2000, year2001, year2002, year2003, year2004, year2005, year2006, year2007, year2008, year2009, \n",
                " #               year2010, year2011, year2012, year2013, year2014, year2015, year2016, year2017, year2018, year2019, year2020, year2021, year2022, year2023, year2024]\n",
                "\n",
                "#for year in all_datasets:\n",
                "#    year.columns = year.columns.str.strip()\n",
                "#    year.columns = year.columns.str.upper()\n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 22,
            "metadata": {},
            "outputs": [],
            "source": [
                "# Strip column names and make all column names upper case\n",
                "\n",
                "year2024.columns = year2024.columns.str.strip()\n",
                "year2024.columns = year2024.columns.str.upper()\n",
                "\n",
                "year2023.columns = year2023.columns.str.strip()\n",
                "year2023.columns = year2023.columns.str.upper()\n",
                "\n",
                "year2022.columns = year2022.columns.str.strip()\n",
                "year2022.columns = year2022.columns.str.upper()\n",
                "\n",
                "year2021.columns = year2021.columns.str.strip()\n",
                "year2021.columns = year2021.columns.str.upper()\n",
                "\n",
                "year2020.columns = year2020.columns.str.strip()\n",
                "year2020.columns = year2020.columns.str.upper()\n",
                "\n",
                "year2019.columns = year2019.columns.str.strip()\n",
                "year2019.columns = year2019.columns.str.upper()\n",
                "\n",
                "year2018.columns = year2018.columns.str.strip()\n",
                "year2018.columns = year2018.columns.str.upper()\n",
                "\n",
                "year2017.columns = year2017.columns.str.strip()\n",
                "year2017.columns = year2017.columns.str.upper()\n",
                "\n",
                "year2016.columns = year2016.columns.str.strip()\n",
                "year2016.columns = year2016.columns.str.upper()\n",
                "\n",
                "year2015.columns = year2015.columns.str.strip()\n",
                "year2015.columns = year2015.columns.str.upper()\n",
                "\n",
                "year2014.columns = year2014.columns.str.strip()\n",
                "year2014.columns = year2014.columns.str.upper()\n",
                "\n",
                "year2013.columns = year2013.columns.str.strip()\n",
                "year2013.columns = year2013.columns.str.upper()\n",
                "\n",
                "year2012.columns = year2012.columns.str.strip()\n",
                "year2012.columns = year2012.columns.str.upper()\n",
                "\n",
                "year2011.columns = year2011.columns.str.strip()\n",
                "year2011.columns = year2011.columns.str.upper()\n",
                "\n",
                "year2010.columns = year2010.columns.str.strip()\n",
                "year2010.columns = year2010.columns.str.upper()\n",
                "\n",
                "year2009.columns = year2009.columns.str.strip()\n",
                "year2009.columns = year2009.columns.str.upper()\n",
                "\n",
                "year2008.columns = year2008.columns.str.strip()\n",
                "year2008.columns = year2008.columns.str.upper()\n",
                "\n",
                "year2007.columns = year2007.columns.str.strip()\n",
                "year2007.columns = year2007.columns.str.upper()\n",
                "\n",
                "year2006.columns = year2006.columns.str.strip()\n",
                "year2006.columns = year2006.columns.str.upper()\n",
                "\n",
                "year2005.columns = year2005.columns.str.strip()\n",
                "year2005.columns = year2005.columns.str.upper()\n",
                "\n",
                "year2004.columns = year2004.columns.str.strip()\n",
                "year2004.columns = year2004.columns.str.upper()\n",
                "\n",
                "year2003.columns = year2003.columns.str.strip()\n",
                "year2003.columns = year2003.columns.str.upper()\n",
                "\n",
                "year2002.columns = year2002.columns.str.strip()\n",
                "year2002.columns = year2002.columns.str.upper()\n",
                "\n",
                "year2001.columns = year2001.columns.str.strip()\n",
                "year2001.columns = year2001.columns.str.upper()\n",
                "\n",
                "year2000.columns = year2000.columns.str.strip()\n",
                "year2000.columns = year2000.columns.str.upper()\n",
                "\n",
                "year1999.columns = year1999.columns.str.strip()\n",
                "year1999.columns = year1999.columns.str.upper()\n",
                "\n",
                "year1998.columns = year1998.columns.str.strip()\n",
                "year1998.columns = year1998.columns.str.upper()\n",
                "\n",
                "year1997.columns = year1997.columns.str.strip()\n",
                "year1997.columns = year1997.columns.str.upper()\n",
                "\n",
                "year1996.columns = year1996.columns.str.strip()\n",
                "year1996.columns = year1996.columns.str.upper()"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Part 2: Create Consistent Column/Series Names/Rows\n",
                "\n",
                "Files from 1996-2007 used one set of variable names, 2008-2010 used slightly different names, and then 2011-2024 used a different set. Also, in this dataset, there are multiple rows for each institution, with either one or two rows for each institution-CIPCODE-major# combination. Institution code is the university code, CIPCODE is the major code, and major# is either 1st or 2nd. For # example, one row might represent U of IL, CIPCODE=52.1501 which is a real-estate major, listed as first major. Then the subsequent columns represent the numbers of student graduates in each demographic category (e.g., total, total men, total women, total Asian-Pacific Islander men, etc.). For these reasons, I did a multi-step process:\n",
                "\n",
                "a) Limit to first major only (MAJORNUM=1) for consistency across years (not all datasets reported second major) and limit to Bachelor's degrees conferred (AWLEVEL=5), as Associates, Certificates, and graduate degrees are beyond the scope of this project.\n",
                "\n",
                "b) RECENT DATASETS (2011-2024): Make the recent datasets (2011-2024) exactly as I want them, with only the needed columns, and a new column called \"year\" that will be used upon merging. While I'm at it, I'm going to go ahead and check for missing values, too.\n",
                "\n",
                "c) INTERMEDIATE YEARS (2008-2010): Make these files have the same column titles as the recent files. This is tricky, as will be explained more in-depth below.\n",
                "\n",
                "d) OLD YEARS (1996-2007) Make the \"old\" (1996-2007) files have the same column names as the recent, but also create \"total\" columns where there are none \n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 23,
            "metadata": {},
            "outputs": [],
            "source": [
                "#  A:  Limit to MAJORNUM=1 and AWLEVEL=5. RESULTING DATAFRAMES HAVE SUFFIX \"a\".\n",
                "\n",
                "#note that the MAJORNUM variable was only used from 2001-2024\n",
                "year2024a = year2024[year2024[\"MAJORNUM\"] == 1]\n",
                "year2024a = year2024a[year2024a[\"AWLEVEL\"] ==5]\n",
                "\n",
                "year2023a = year2023[year2023[\"MAJORNUM\"] == 1]\n",
                "year2023a = year2023a[year2023a[\"AWLEVEL\"] ==5]\n",
                "\n",
                "year2022a = year2022[year2022[\"MAJORNUM\"] == 1]\n",
                "year2022a = year2022a[year2022a[\"AWLEVEL\"] ==5]\n",
                "\n",
                "year2021a = year2021[year2021[\"MAJORNUM\"] == 1]\n",
                "year2021a = year2021a[year2021a[\"AWLEVEL\"] ==5]\n",
                "\n",
                "year2020a = year2020[year2020[\"MAJORNUM\"] == 1]\n",
                "year2020a = year2020a[year2020a[\"AWLEVEL\"] ==5]\n",
                "\n",
                "year2019a = year2019[year2019[\"MAJORNUM\"] == 1]\n",
                "year2019a = year2019a[year2019a[\"AWLEVEL\"] ==5]\n",
                "\n",
                "year2018a = year2018[year2018[\"MAJORNUM\"] == 1]\n",
                "year2018a = year2018a[year2018a[\"AWLEVEL\"] ==5]\n",
                "\n",
                "year2017a = year2017[year2017[\"MAJORNUM\"] == 1]\n",
                "year2017a = year2017a[year2017a[\"AWLEVEL\"] ==5]\n",
                "\n",
                "year2016a = year2016[year2016[\"MAJORNUM\"] == 1]\n",
                "year2016a = year2016a[year2016a[\"AWLEVEL\"] ==5]\n",
                "\n",
                "year2015a = year2015[year2015[\"MAJORNUM\"] == 1]\n",
                "year2015a = year2015a[year2015a[\"AWLEVEL\"] ==5]\n",
                "\n",
                "year2014a = year2014[year2014[\"MAJORNUM\"] == 1]\n",
                "year2014a = year2014a[year2014a[\"AWLEVEL\"] ==5]\n",
                "\n",
                "year2013a = year2013[year2013[\"MAJORNUM\"] == 1]\n",
                "year2013a = year2013a[year2013a[\"AWLEVEL\"] ==5]\n",
                "\n",
                "year2012a = year2012[year2012[\"MAJORNUM\"] == 1]\n",
                "year2012a = year2012a[year2012a[\"AWLEVEL\"] ==5]\n",
                "\n",
                "year2011a = year2011[year2011[\"MAJORNUM\"] == 1]\n",
                "year2011a = year2011a[year2011a[\"AWLEVEL\"] ==5]\n",
                "\n",
                "year2010a = year2010[year2010[\"MAJORNUM\"] == 1]\n",
                "year2010a = year2010a[year2010a[\"AWLEVEL\"] ==5]\n",
                "\n",
                "year2009a = year2009[year2009[\"MAJORNUM\"] == 1]\n",
                "year2009a = year2009a[year2009a[\"AWLEVEL\"] ==5]\n",
                "\n",
                "year2008a = year2008[year2008[\"MAJORNUM\"] == 1]\n",
                "year2008a = year2008a[year2008a[\"AWLEVEL\"] ==5]\n",
                "\n",
                "year2007a = year2007[year2007[\"MAJORNUM\"] == 1]\n",
                "year2007a = year2007a[year2007a[\"AWLEVEL\"] ==5]\n",
                "\n",
                "year2006a = year2006[year2006[\"MAJORNUM\"] == 1]\n",
                "year2006a = year2006a[year2006a[\"AWLEVEL\"] ==5]\n",
                "\n",
                "year2005a = year2005[year2005[\"MAJORNUM\"] == 1]\n",
                "year2005a = year2005a[year2005a[\"AWLEVEL\"] ==5]\n",
                "\n",
                "year2004a = year2004[year2004[\"MAJORNUM\"] == 1]\n",
                "year2004a = year2004a[year2004a[\"AWLEVEL\"] ==5]\n",
                "\n",
                "year2003a = year2003[year2003[\"MAJORNUM\"] == 1]\n",
                "year2003a = year2003a[year2003a[\"AWLEVEL\"] ==5]\n",
                "\n",
                "year2002a = year2002[year2002[\"MAJORNUM\"] == 1]\n",
                "year2002a = year2002a[year2002a[\"AWLEVEL\"] ==5]\n",
                "\n",
                "year2001a = year2001[year2001[\"MAJORNUM\"] == 1]\n",
                "year2001a = year2001a[year2001a[\"AWLEVEL\"] ==5]\n",
                "\n",
                "# but AWLEVEL was used in all years\n",
                "\n",
                "year2000a = year2000[year2000[\"AWLEVEL\"] ==5]  \n",
                "year1999a = year1999[year1999[\"AWLEVEL\"] ==5]\n",
                "year1998a = year1998[year1998[\"AWLEVEL\"] ==5]\n",
                "year1997a = year1997[year1997[\"AWLEVEL\"] ==5]  \n",
                "year1996a = year1996[year1996[\"AWLEVEL\"] ==5]"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 24,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "(84312, 64)\n",
                        "(83854, 64)\n",
                        "(83921, 64)\n",
                        "(83349, 64)\n",
                        "(83061, 64)\n",
                        "(82981, 64)\n",
                        "(82247, 64)\n",
                        "(81547, 64)\n",
                        "(80229, 64)\n",
                        "(80541, 64)\n",
                        "(79319, 64)\n",
                        "(78100, 64)\n",
                        "(75432, 65)\n",
                        "(74211, 64)\n",
                        "(73828, 124)\n",
                        "(71815, 124)\n",
                        "(69464, 124)\n",
                        "(68646, 52)\n",
                        "(67578, 52)\n",
                        "(66018, 52)\n",
                        "(63905, 52)\n",
                        "(62059, 52)\n",
                        "(60267, 52)\n",
                        "(59959, 36)\n",
                        "(58189, 35)\n",
                        "(52525, 51)\n",
                        "(58298, 37)\n",
                        "(53460, 38)\n",
                        "(53191, 38)\n"
                    ]
                }
            ],
            "source": [
                "#Checking to see how many rows were in each dataframe after that step:\n",
                "print(year2024a.shape)\n",
                "print(year2023a.shape)\n",
                "print(year2022a.shape)\n",
                "print(year2021a.shape)\n",
                "print(year2020a.shape)\n",
                "print(year2019a.shape)\n",
                "print(year2018a.shape)\n",
                "print(year2017a.shape)                      \n",
                "print(year2016a.shape)\n",
                "print(year2015a.shape)\n",
                "print(year2014a.shape)\n",
                "print(year2013a.shape)\n",
                "print(year2012a.shape)                      \n",
                "print(year2011a.shape)\n",
                "print(year2010a.shape)\n",
                "print(year2009a.shape)\n",
                "print(year2008a.shape)\n",
                "print(year2007a.shape)                      \n",
                "print(year2006a.shape)\n",
                "print(year2005a.shape)\n",
                "print(year2004a.shape)\n",
                "print(year2003a.shape)  \n",
                "print(year2002a.shape)\n",
                "print(year2001a.shape)\n",
                "print(year2000a.shape)\n",
                "print(year1999a.shape)\n",
                "print(year1998a.shape)\n",
                "print(year1997a.shape) \n",
                "print(year1996a.shape)\n",
                "\n",
                "# The output shows that after this step, this is the row/column count for each year for dataset \"a\":\n",
                "# 2024\t(84312, 64)\n",
                "# 2023\t(83854, 64)\n",
                "# 2022\t(83921, 64)\n",
                "# 2021\t(83349, 64)\n",
                "# 2020\t(83061, 64)\n",
                "# 2019\t(82981, 64)\n",
                "# 2018\t(82247, 64)\n",
                "# 2017\t(81547, 64)\n",
                "# 2016\t(80229, 64)\n",
                "# 2015\t(80541, 64)\n",
                "# 2014\t(79319, 64)\n",
                "# 2013\t(78100, 64)\n",
                "# 2012\t(75432, 65)\n",
                "# 2011\t(74211, 64)\n",
                "# 2010\t(73828, 124)\n",
                "# 2009\t(71815, 124)\n",
                "# 2008\t(69464, 124)\n",
                "# 2007\t(68646, 52)\n",
                "# 2006\t(67578, 52)\n",
                "# 2005\t(66018, 52)\n",
                "# 2004\t(63905, 52)\n",
                "# 2003\t(62059, 52)\n",
                "# 2002\t(60267, 52)\n",
                "# 2001\t(59959, 36)\n",
                "# 2000\t(58189, 35)\n",
                "# 1999\t(52525, 51)\n",
                "# 1998\t(58298, 37)\n",
                "# 1997\t(53460, 38)\n",
                "# 1996\t(53191, 38)\n",
                "\n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 25,
            "metadata": {},
            "outputs": [
                {
                    "name": "stderr",
                    "output_type": "stream",
                    "text": [
                        "C:\\Users\\B\\AppData\\Local\\Temp\\ipykernel_14816\\1652534293.py:45: SettingWithCopyWarning: \n",
                        "A value is trying to be set on a copy of a slice from a DataFrame.\n",
                        "Try using .loc[row_indexer,col_indexer] = value instead\n",
                        "\n",
                        "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
                        "  year2024b[\"year\"] = 2024\n",
                        "C:\\Users\\B\\AppData\\Local\\Temp\\ipykernel_14816\\1652534293.py:46: SettingWithCopyWarning: \n",
                        "A value is trying to be set on a copy of a slice from a DataFrame.\n",
                        "Try using .loc[row_indexer,col_indexer] = value instead\n",
                        "\n",
                        "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
                        "  year2023b[\"year\"] = 2023\n",
                        "C:\\Users\\B\\AppData\\Local\\Temp\\ipykernel_14816\\1652534293.py:47: SettingWithCopyWarning: \n",
                        "A value is trying to be set on a copy of a slice from a DataFrame.\n",
                        "Try using .loc[row_indexer,col_indexer] = value instead\n",
                        "\n",
                        "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
                        "  year2022b[\"year\"] = 2022\n",
                        "C:\\Users\\B\\AppData\\Local\\Temp\\ipykernel_14816\\1652534293.py:48: SettingWithCopyWarning: \n",
                        "A value is trying to be set on a copy of a slice from a DataFrame.\n",
                        "Try using .loc[row_indexer,col_indexer] = value instead\n",
                        "\n",
                        "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
                        "  year2021b[\"year\"] = 2021\n",
                        "C:\\Users\\B\\AppData\\Local\\Temp\\ipykernel_14816\\1652534293.py:49: SettingWithCopyWarning: \n",
                        "A value is trying to be set on a copy of a slice from a DataFrame.\n",
                        "Try using .loc[row_indexer,col_indexer] = value instead\n",
                        "\n",
                        "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
                        "  year2020b[\"year\"] = 2020\n",
                        "C:\\Users\\B\\AppData\\Local\\Temp\\ipykernel_14816\\1652534293.py:50: SettingWithCopyWarning: \n",
                        "A value is trying to be set on a copy of a slice from a DataFrame.\n",
                        "Try using .loc[row_indexer,col_indexer] = value instead\n",
                        "\n",
                        "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
                        "  year2019b[\"year\"] = 2019\n",
                        "C:\\Users\\B\\AppData\\Local\\Temp\\ipykernel_14816\\1652534293.py:51: SettingWithCopyWarning: \n",
                        "A value is trying to be set on a copy of a slice from a DataFrame.\n",
                        "Try using .loc[row_indexer,col_indexer] = value instead\n",
                        "\n",
                        "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
                        "  year2018b[\"year\"] = 2018\n",
                        "C:\\Users\\B\\AppData\\Local\\Temp\\ipykernel_14816\\1652534293.py:52: SettingWithCopyWarning: \n",
                        "A value is trying to be set on a copy of a slice from a DataFrame.\n",
                        "Try using .loc[row_indexer,col_indexer] = value instead\n",
                        "\n",
                        "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
                        "  year2017b[\"year\"] = 2017\n",
                        "C:\\Users\\B\\AppData\\Local\\Temp\\ipykernel_14816\\1652534293.py:53: SettingWithCopyWarning: \n",
                        "A value is trying to be set on a copy of a slice from a DataFrame.\n",
                        "Try using .loc[row_indexer,col_indexer] = value instead\n",
                        "\n",
                        "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
                        "  year2016b[\"year\"] = 2016\n",
                        "C:\\Users\\B\\AppData\\Local\\Temp\\ipykernel_14816\\1652534293.py:54: SettingWithCopyWarning: \n",
                        "A value is trying to be set on a copy of a slice from a DataFrame.\n",
                        "Try using .loc[row_indexer,col_indexer] = value instead\n",
                        "\n",
                        "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
                        "  year2015b[\"year\"] = 2015\n",
                        "C:\\Users\\B\\AppData\\Local\\Temp\\ipykernel_14816\\1652534293.py:55: SettingWithCopyWarning: \n",
                        "A value is trying to be set on a copy of a slice from a DataFrame.\n",
                        "Try using .loc[row_indexer,col_indexer] = value instead\n",
                        "\n",
                        "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
                        "  year2014b[\"year\"] = 2014\n",
                        "C:\\Users\\B\\AppData\\Local\\Temp\\ipykernel_14816\\1652534293.py:56: SettingWithCopyWarning: \n",
                        "A value is trying to be set on a copy of a slice from a DataFrame.\n",
                        "Try using .loc[row_indexer,col_indexer] = value instead\n",
                        "\n",
                        "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
                        "  year2013b[\"year\"] = 2013\n",
                        "C:\\Users\\B\\AppData\\Local\\Temp\\ipykernel_14816\\1652534293.py:57: SettingWithCopyWarning: \n",
                        "A value is trying to be set on a copy of a slice from a DataFrame.\n",
                        "Try using .loc[row_indexer,col_indexer] = value instead\n",
                        "\n",
                        "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
                        "  year2012b[\"year\"] = 2012\n",
                        "C:\\Users\\B\\AppData\\Local\\Temp\\ipykernel_14816\\1652534293.py:58: SettingWithCopyWarning: \n",
                        "A value is trying to be set on a copy of a slice from a DataFrame.\n",
                        "Try using .loc[row_indexer,col_indexer] = value instead\n",
                        "\n",
                        "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
                        "  year2011b[\"year\"] = 2011\n"
                    ]
                },
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "UNITID     0\n",
                        "CIPCODE    0\n",
                        "CTOTALT    0\n",
                        "CTOTALM    0\n",
                        "CTOTALW    0\n",
                        "CAIANT     0\n",
                        "CAIANM     0\n",
                        "CAIANW     0\n",
                        "CASIAT     0\n",
                        "CASIAM     0\n",
                        "CASIAW     0\n",
                        "CBKAAT     0\n",
                        "CBKAAM     0\n",
                        "CBKAAW     0\n",
                        "CHISPT     0\n",
                        "CHISPM     0\n",
                        "CHISPW     0\n",
                        "CNHPIT     0\n",
                        "CNHPIM     0\n",
                        "CNHPIW     0\n",
                        "CWHITT     0\n",
                        "CWHITM     0\n",
                        "CWHITW     0\n",
                        "year       0\n",
                        "dtype: int64\n",
                        "UNITID     0\n",
                        "CIPCODE    0\n",
                        "CTOTALT    0\n",
                        "CTOTALM    0\n",
                        "CTOTALW    0\n",
                        "CAIANT     0\n",
                        "CAIANM     0\n",
                        "CAIANW     0\n",
                        "CASIAT     0\n",
                        "CASIAM     0\n",
                        "CASIAW     0\n",
                        "CBKAAT     0\n",
                        "CBKAAM     0\n",
                        "CBKAAW     0\n",
                        "CHISPT     0\n",
                        "CHISPM     0\n",
                        "CHISPW     0\n",
                        "CNHPIT     0\n",
                        "CNHPIM     0\n",
                        "CNHPIW     0\n",
                        "CWHITT     0\n",
                        "CWHITM     0\n",
                        "CWHITW     0\n",
                        "year       0\n",
                        "dtype: int64\n",
                        "UNITID     0\n",
                        "CIPCODE    0\n",
                        "CTOTALT    0\n",
                        "CTOTALM    0\n",
                        "CTOTALW    0\n",
                        "CAIANT     0\n",
                        "CAIANM     0\n",
                        "CAIANW     0\n",
                        "CASIAT     0\n",
                        "CASIAM     0\n",
                        "CASIAW     0\n",
                        "CBKAAT     0\n",
                        "CBKAAM     0\n",
                        "CBKAAW     0\n",
                        "CHISPT     0\n",
                        "CHISPM     0\n",
                        "CHISPW     0\n",
                        "CNHPIT     0\n",
                        "CNHPIM     0\n",
                        "CNHPIW     0\n",
                        "CWHITT     0\n",
                        "CWHITM     0\n",
                        "CWHITW     0\n",
                        "year       0\n",
                        "dtype: int64\n",
                        "UNITID     0\n",
                        "CIPCODE    0\n",
                        "CTOTALT    0\n",
                        "CTOTALM    0\n",
                        "CTOTALW    0\n",
                        "CAIANT     0\n",
                        "CAIANM     0\n",
                        "CAIANW     0\n",
                        "CASIAT     0\n",
                        "CASIAM     0\n",
                        "CASIAW     0\n",
                        "CBKAAT     0\n",
                        "CBKAAM     0\n",
                        "CBKAAW     0\n",
                        "CHISPT     0\n",
                        "CHISPM     0\n",
                        "CHISPW     0\n",
                        "CNHPIT     0\n",
                        "CNHPIM     0\n",
                        "CNHPIW     0\n",
                        "CWHITT     0\n",
                        "CWHITM     0\n",
                        "CWHITW     0\n",
                        "year       0\n",
                        "dtype: int64\n",
                        "UNITID     0\n",
                        "CIPCODE    0\n",
                        "CTOTALT    0\n",
                        "CTOTALM    0\n",
                        "CTOTALW    0\n",
                        "CAIANT     0\n",
                        "CAIANM     0\n",
                        "CAIANW     0\n",
                        "CASIAT     0\n",
                        "CASIAM     0\n",
                        "CASIAW     0\n",
                        "CBKAAT     0\n",
                        "CBKAAM     0\n",
                        "CBKAAW     0\n",
                        "CHISPT     0\n",
                        "CHISPM     0\n",
                        "CHISPW     0\n",
                        "CNHPIT     0\n",
                        "CNHPIM     0\n",
                        "CNHPIW     0\n",
                        "CWHITT     0\n",
                        "CWHITM     0\n",
                        "CWHITW     0\n",
                        "year       0\n",
                        "dtype: int64\n",
                        "UNITID     0\n",
                        "CIPCODE    0\n",
                        "CTOTALT    0\n",
                        "CTOTALM    0\n",
                        "CTOTALW    0\n",
                        "CAIANT     0\n",
                        "CAIANM     0\n",
                        "CAIANW     0\n",
                        "CASIAT     0\n",
                        "CASIAM     0\n",
                        "CASIAW     0\n",
                        "CBKAAT     0\n",
                        "CBKAAM     0\n",
                        "CBKAAW     0\n",
                        "CHISPT     0\n",
                        "CHISPM     0\n",
                        "CHISPW     0\n",
                        "CNHPIT     0\n",
                        "CNHPIM     0\n",
                        "CNHPIW     0\n",
                        "CWHITT     0\n",
                        "CWHITM     0\n",
                        "CWHITW     0\n",
                        "year       0\n",
                        "dtype: int64\n",
                        "UNITID     0\n",
                        "CIPCODE    0\n",
                        "CTOTALT    0\n",
                        "CTOTALM    0\n",
                        "CTOTALW    0\n",
                        "CAIANT     0\n",
                        "CAIANM     0\n",
                        "CAIANW     0\n",
                        "CASIAT     0\n",
                        "CASIAM     0\n",
                        "CASIAW     0\n",
                        "CBKAAT     0\n",
                        "CBKAAM     0\n",
                        "CBKAAW     0\n",
                        "CHISPT     0\n",
                        "CHISPM     0\n",
                        "CHISPW     0\n",
                        "CNHPIT     0\n",
                        "CNHPIM     0\n",
                        "CNHPIW     0\n",
                        "CWHITT     0\n",
                        "CWHITM     0\n",
                        "CWHITW     0\n",
                        "year       0\n",
                        "dtype: int64\n",
                        "UNITID     0\n",
                        "CIPCODE    0\n",
                        "CTOTALT    0\n",
                        "CTOTALM    0\n",
                        "CTOTALW    0\n",
                        "CAIANT     0\n",
                        "CAIANM     0\n",
                        "CAIANW     0\n",
                        "CASIAT     0\n",
                        "CASIAM     0\n",
                        "CASIAW     0\n",
                        "CBKAAT     0\n",
                        "CBKAAM     0\n",
                        "CBKAAW     0\n",
                        "CHISPT     0\n",
                        "CHISPM     0\n",
                        "CHISPW     0\n",
                        "CNHPIT     0\n",
                        "CNHPIM     0\n",
                        "CNHPIW     0\n",
                        "CWHITT     0\n",
                        "CWHITM     0\n",
                        "CWHITW     0\n",
                        "year       0\n",
                        "dtype: int64\n",
                        "UNITID     0\n",
                        "CIPCODE    0\n",
                        "CTOTALT    0\n",
                        "CTOTALM    0\n",
                        "CTOTALW    0\n",
                        "CAIANT     0\n",
                        "CAIANM     0\n",
                        "CAIANW     0\n",
                        "CASIAT     0\n",
                        "CASIAM     0\n",
                        "CASIAW     0\n",
                        "CBKAAT     0\n",
                        "CBKAAM     0\n",
                        "CBKAAW     0\n",
                        "CHISPT     0\n",
                        "CHISPM     0\n",
                        "CHISPW     0\n",
                        "CNHPIT     0\n",
                        "CNHPIM     0\n",
                        "CNHPIW     0\n",
                        "CWHITT     0\n",
                        "CWHITM     0\n",
                        "CWHITW     0\n",
                        "year       0\n",
                        "dtype: int64\n",
                        "UNITID     0\n",
                        "CIPCODE    0\n",
                        "CTOTALT    0\n",
                        "CTOTALM    0\n",
                        "CTOTALW    0\n",
                        "CAIANT     0\n",
                        "CAIANM     0\n",
                        "CAIANW     0\n",
                        "CASIAT     0\n",
                        "CASIAM     0\n",
                        "CASIAW     0\n",
                        "CBKAAT     0\n",
                        "CBKAAM     0\n",
                        "CBKAAW     0\n",
                        "CHISPT     0\n",
                        "CHISPM     0\n",
                        "CHISPW     0\n",
                        "CNHPIT     0\n",
                        "CNHPIM     0\n",
                        "CNHPIW     0\n",
                        "CWHITT     0\n",
                        "CWHITM     0\n",
                        "CWHITW     0\n",
                        "year       0\n",
                        "dtype: int64\n",
                        "UNITID     0\n",
                        "CIPCODE    0\n",
                        "CTOTALT    0\n",
                        "CTOTALM    0\n",
                        "CTOTALW    0\n",
                        "CAIANT     0\n",
                        "CAIANM     0\n",
                        "CAIANW     0\n",
                        "CASIAT     0\n",
                        "CASIAM     0\n",
                        "CASIAW     0\n",
                        "CBKAAT     0\n",
                        "CBKAAM     0\n",
                        "CBKAAW     0\n",
                        "CHISPT     0\n",
                        "CHISPM     0\n",
                        "CHISPW     0\n",
                        "CNHPIT     0\n",
                        "CNHPIM     0\n",
                        "CNHPIW     0\n",
                        "CWHITT     0\n",
                        "CWHITM     0\n",
                        "CWHITW     0\n",
                        "year       0\n",
                        "dtype: int64\n",
                        "UNITID     0\n",
                        "CIPCODE    0\n",
                        "CTOTALT    0\n",
                        "CTOTALM    0\n",
                        "CTOTALW    0\n",
                        "CAIANT     0\n",
                        "CAIANM     0\n",
                        "CAIANW     0\n",
                        "CASIAT     0\n",
                        "CASIAM     0\n",
                        "CASIAW     0\n",
                        "CBKAAT     0\n",
                        "CBKAAM     0\n",
                        "CBKAAW     0\n",
                        "CHISPT     0\n",
                        "CHISPM     0\n",
                        "CHISPW     0\n",
                        "CNHPIT     0\n",
                        "CNHPIM     0\n",
                        "CNHPIW     0\n",
                        "CWHITT     0\n",
                        "CWHITM     0\n",
                        "CWHITW     0\n",
                        "year       0\n",
                        "dtype: int64\n",
                        "UNITID     0\n",
                        "CIPCODE    0\n",
                        "CTOTALT    0\n",
                        "CTOTALM    0\n",
                        "CTOTALW    0\n",
                        "CAIANT     0\n",
                        "CAIANM     0\n",
                        "CAIANW     0\n",
                        "CASIAT     0\n",
                        "CASIAM     0\n",
                        "CASIAW     0\n",
                        "CBKAAT     0\n",
                        "CBKAAM     0\n",
                        "CBKAAW     0\n",
                        "CHISPT     0\n",
                        "CHISPM     0\n",
                        "CHISPW     0\n",
                        "CNHPIT     0\n",
                        "CNHPIM     0\n",
                        "CNHPIW     0\n",
                        "CWHITT     0\n",
                        "CWHITM     0\n",
                        "CWHITW     0\n",
                        "year       0\n",
                        "dtype: int64\n",
                        "UNITID     0\n",
                        "CIPCODE    0\n",
                        "CTOTALT    0\n",
                        "CTOTALM    0\n",
                        "CTOTALW    0\n",
                        "CAIANT     0\n",
                        "CAIANM     0\n",
                        "CAIANW     0\n",
                        "CASIAT     0\n",
                        "CASIAM     0\n",
                        "CASIAW     0\n",
                        "CBKAAT     0\n",
                        "CBKAAM     0\n",
                        "CBKAAW     0\n",
                        "CHISPT     0\n",
                        "CHISPM     0\n",
                        "CHISPW     0\n",
                        "CNHPIT     0\n",
                        "CNHPIM     0\n",
                        "CNHPIW     0\n",
                        "CWHITT     0\n",
                        "CWHITM     0\n",
                        "CWHITW     0\n",
                        "year       0\n",
                        "dtype: int64\n"
                    ]
                }
            ],
            "source": [
                "# B: RECENT YEARS (2011-2024): RESULTING DATAFRAMES HAVE SUFFIX \"b\".\n",
                "\n",
                "# 1. Datasets from 2011-2024 all have the same columns. I wish to only keep the columns of interest to me, which include the UNITID (institution), CIPCODE (major),\n",
                "# and then # of men(M), women (W), and total (T) for each race/ethnicity category (CTOTAL, CAIAN=American Indian or Alaska Native, CASIA=Asian, CBKAAT=Black, \n",
                "# CBHISP=Hispanic/Latino, CNHPI=Native Hawaiian/Pacific Islander, CWHIT=white). The following columns will not be included: \n",
                "\n",
                "#COLUMN NAME AND WHY DROPPED\n",
                "    #CUNKNT (race/ethnicity unknown, total): not helpful when looking at racial/ethnic trends\n",
                "    #CUNKNM (race/ethnicity unknown, MEN): not helpful when looking at racial/ethnic trends\n",
                "    #CUNKNW (race/ethnicity unknown, WOMEN): not helpful when looking at racial/ethnic trends\n",
                "    #C2MORT (2+ races, total): not reported until 2011, eliminated in interest of having complete data for all years\n",
                "    #C2MORM (2+ races, men): not reported until 2011, eliminated in interest of having complete data for all years\n",
                "    #C2MORW (2+ races, women): not reported until 2011, eliminated in interest of having complete data for all years\n",
                "    #CNRALT (non-resident, total): interesting, but not reported for all years, eliminated in interest of having complete data for all years\n",
                "    #CNRALW (non-resident, total): interesting, but not reported for all years, eliminated in interest of having complete data for all years\n",
                "    #CNRALM (non-resident, total): interesting, but not reported for all years, eliminated in interest of having complete data for all years\n",
                "    #Columns that begin with \"X\". In some of the years' datasets, there is an imputation code column for each variable/column. In other words, there is a column \n",
                "        # called CTOTALC, which is the total # of students who earned a degree in that row's institution & CIPID (major code). There is a corresponding column \n",
                "        # called XCTOTALC, in which a letter is given to all values of CTOTALC to indicate whether the value there was as reported, or, if imputed, the method \n",
                "        # of imputation. Because imputation method is beyond the scope of this analysis, I will remove all columns that begin with \"X\".\n",
                "    #AWLEVEL now has a value of 5 for all datasets and all rows, so it's not very useful\n",
                "    #MAJORNUM now has a value of 1 for all datasets, so again it's not very useful\n",
                "\n",
                "columns_to_keep = ['UNITID', 'CIPCODE', 'CTOTALT', 'CTOTALM', 'CTOTALW', 'CAIANT', 'CAIANM', 'CAIANW', 'CASIAT', 'CASIAM', 'CASIAW', 'CBKAAT', 'CBKAAM','CBKAAW',\n",
                "                      'CHISPT', 'CHISPM', 'CHISPW', 'CNHPIT', 'CNHPIM', 'CNHPIW','CWHITT', 'CWHITM', 'CWHITW']\n",
                "\n",
                "#I tried to do the following in a loop but I couldn't get it to save the changes permanently to the dataframes...not sure why\n",
                "year2024b = year2024a[columns_to_keep]\n",
                "year2023b = year2023a[columns_to_keep]\n",
                "year2022b = year2022a[columns_to_keep]\n",
                "year2021b = year2021a[columns_to_keep]\n",
                "year2020b = year2020a[columns_to_keep]\n",
                "year2019b = year2019a[columns_to_keep]\n",
                "year2018b = year2018a[columns_to_keep]\n",
                "year2017b = year2017a[columns_to_keep]\n",
                "year2016b = year2016a[columns_to_keep]\n",
                "year2015b = year2015a[columns_to_keep]\n",
                "year2014b = year2014a[columns_to_keep]\n",
                "year2013b = year2013a[columns_to_keep]\n",
                "year2012b = year2012a[columns_to_keep]\n",
                "year2011b = year2011a[columns_to_keep]\n",
                "\n",
                "\n",
                "# 2: ADD \"YEAR\" COLUMN TO EACH DATASET SO THAT I CAN TELL THEM APART WHEN I MERGE THEM\n",
                "year2024b[\"year\"] = 2024\n",
                "year2023b[\"year\"] = 2023\n",
                "year2022b[\"year\"] = 2022\n",
                "year2021b[\"year\"] = 2021\n",
                "year2020b[\"year\"] = 2020\n",
                "year2019b[\"year\"] = 2019\n",
                "year2018b[\"year\"] = 2018\n",
                "year2017b[\"year\"] = 2017\n",
                "year2016b[\"year\"] = 2016\n",
                "year2015b[\"year\"] = 2015\n",
                "year2014b[\"year\"] = 2014\n",
                "year2013b[\"year\"] = 2013\n",
                "year2012b[\"year\"] = 2012\n",
                "year2011b[\"year\"] = 2011\n",
                "\n",
                "\n",
                "# 3. Check for missing values\n",
                "print(year2024b[['UNITID', 'CIPCODE', 'CTOTALT', 'CTOTALM', 'CTOTALW', 'CAIANT', 'CAIANM', 'CAIANW', 'CASIAT', 'CASIAM', 'CASIAW', 'CBKAAT','CBKAAM', 'CBKAAW', 'CHISPT', 'CHISPM', 'CHISPW', 'CNHPIT', 'CNHPIM', 'CNHPIW', 'CWHITT', 'CWHITM', 'CWHITW', 'year']].isna().sum())\n",
                "print(year2023b[['UNITID', 'CIPCODE', 'CTOTALT', 'CTOTALM', 'CTOTALW', 'CAIANT', 'CAIANM', 'CAIANW', 'CASIAT', 'CASIAM', 'CASIAW', 'CBKAAT','CBKAAM', 'CBKAAW', 'CHISPT', 'CHISPM', 'CHISPW', 'CNHPIT', 'CNHPIM', 'CNHPIW', 'CWHITT', 'CWHITM', 'CWHITW', 'year']].isna().sum())\n",
                "print(year2022b[['UNITID', 'CIPCODE', 'CTOTALT', 'CTOTALM', 'CTOTALW', 'CAIANT', 'CAIANM', 'CAIANW', 'CASIAT', 'CASIAM', 'CASIAW', 'CBKAAT','CBKAAM', 'CBKAAW', 'CHISPT', 'CHISPM', 'CHISPW', 'CNHPIT', 'CNHPIM', 'CNHPIW', 'CWHITT', 'CWHITM', 'CWHITW', 'year']].isna().sum())\n",
                "print(year2021b[['UNITID', 'CIPCODE', 'CTOTALT', 'CTOTALM', 'CTOTALW', 'CAIANT', 'CAIANM', 'CAIANW', 'CASIAT', 'CASIAM', 'CASIAW', 'CBKAAT','CBKAAM', 'CBKAAW', 'CHISPT', 'CHISPM', 'CHISPW', 'CNHPIT', 'CNHPIM', 'CNHPIW', 'CWHITT', 'CWHITM', 'CWHITW', 'year']].isna().sum())\n",
                "print(year2020b[['UNITID', 'CIPCODE', 'CTOTALT', 'CTOTALM', 'CTOTALW', 'CAIANT', 'CAIANM', 'CAIANW', 'CASIAT', 'CASIAM', 'CASIAW', 'CBKAAT','CBKAAM', 'CBKAAW', 'CHISPT', 'CHISPM', 'CHISPW', 'CNHPIT', 'CNHPIM', 'CNHPIW', 'CWHITT', 'CWHITM', 'CWHITW', 'year']].isna().sum())\n",
                "print(year2019b[['UNITID', 'CIPCODE', 'CTOTALT', 'CTOTALM', 'CTOTALW', 'CAIANT', 'CAIANM', 'CAIANW', 'CASIAT', 'CASIAM', 'CASIAW', 'CBKAAT','CBKAAM', 'CBKAAW', 'CHISPT', 'CHISPM', 'CHISPW', 'CNHPIT', 'CNHPIM', 'CNHPIW', 'CWHITT', 'CWHITM', 'CWHITW', 'year']].isna().sum())\n",
                "print(year2018b[['UNITID', 'CIPCODE', 'CTOTALT', 'CTOTALM', 'CTOTALW', 'CAIANT', 'CAIANM', 'CAIANW', 'CASIAT', 'CASIAM', 'CASIAW', 'CBKAAT','CBKAAM', 'CBKAAW', 'CHISPT', 'CHISPM', 'CHISPW', 'CNHPIT', 'CNHPIM', 'CNHPIW', 'CWHITT', 'CWHITM', 'CWHITW', 'year']].isna().sum())\n",
                "print(year2017b[['UNITID', 'CIPCODE', 'CTOTALT', 'CTOTALM', 'CTOTALW', 'CAIANT', 'CAIANM', 'CAIANW', 'CASIAT', 'CASIAM', 'CASIAW', 'CBKAAT','CBKAAM', 'CBKAAW', 'CHISPT', 'CHISPM', 'CHISPW', 'CNHPIT', 'CNHPIM', 'CNHPIW', 'CWHITT', 'CWHITM', 'CWHITW', 'year']].isna().sum())\n",
                "print(year2016b[['UNITID', 'CIPCODE', 'CTOTALT', 'CTOTALM', 'CTOTALW', 'CAIANT', 'CAIANM', 'CAIANW', 'CASIAT', 'CASIAM', 'CASIAW', 'CBKAAT','CBKAAM', 'CBKAAW', 'CHISPT', 'CHISPM', 'CHISPW', 'CNHPIT', 'CNHPIM', 'CNHPIW', 'CWHITT', 'CWHITM', 'CWHITW', 'year']].isna().sum())\n",
                "print(year2015b[['UNITID', 'CIPCODE', 'CTOTALT', 'CTOTALM', 'CTOTALW', 'CAIANT', 'CAIANM', 'CAIANW', 'CASIAT', 'CASIAM', 'CASIAW', 'CBKAAT','CBKAAM', 'CBKAAW', 'CHISPT', 'CHISPM', 'CHISPW', 'CNHPIT', 'CNHPIM', 'CNHPIW', 'CWHITT', 'CWHITM', 'CWHITW', 'year']].isna().sum())\n",
                "print(year2014b[['UNITID', 'CIPCODE', 'CTOTALT', 'CTOTALM', 'CTOTALW', 'CAIANT', 'CAIANM', 'CAIANW', 'CASIAT', 'CASIAM', 'CASIAW', 'CBKAAT','CBKAAM', 'CBKAAW', 'CHISPT', 'CHISPM', 'CHISPW', 'CNHPIT', 'CNHPIM', 'CNHPIW', 'CWHITT', 'CWHITM', 'CWHITW', 'year']].isna().sum())\n",
                "print(year2013b[['UNITID', 'CIPCODE', 'CTOTALT', 'CTOTALM', 'CTOTALW', 'CAIANT', 'CAIANM', 'CAIANW', 'CASIAT', 'CASIAM', 'CASIAW', 'CBKAAT','CBKAAM', 'CBKAAW', 'CHISPT', 'CHISPM', 'CHISPW', 'CNHPIT', 'CNHPIM', 'CNHPIW', 'CWHITT', 'CWHITM', 'CWHITW', 'year']].isna().sum())\n",
                "print(year2012b[['UNITID', 'CIPCODE', 'CTOTALT', 'CTOTALM', 'CTOTALW', 'CAIANT', 'CAIANM', 'CAIANW', 'CASIAT', 'CASIAM', 'CASIAW', 'CBKAAT','CBKAAM', 'CBKAAW', 'CHISPT', 'CHISPM', 'CHISPW', 'CNHPIT', 'CNHPIM', 'CNHPIW', 'CWHITT', 'CWHITM', 'CWHITW', 'year']].isna().sum())\n",
                "print(year2011b[['UNITID', 'CIPCODE', 'CTOTALT', 'CTOTALM', 'CTOTALW', 'CAIANT', 'CAIANM', 'CAIANW', 'CASIAT', 'CASIAM', 'CASIAW', 'CBKAAT','CBKAAM', 'CBKAAW', 'CHISPT', 'CHISPM', 'CHISPW', 'CNHPIT', 'CNHPIM', 'CNHPIW', 'CWHITT', 'CWHITM', 'CWHITW', 'year']].isna().sum())\n",
                "\n",
                "# There are no missing values!"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 26,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "(84312, 24)\n",
                        "(83854, 24)\n",
                        "(83921, 24)\n",
                        "(83349, 24)\n",
                        "(83061, 24)\n",
                        "(82981, 24)\n",
                        "(82247, 24)\n",
                        "(81547, 24)\n",
                        "(80229, 24)\n",
                        "(80541, 24)\n",
                        "(79319, 24)\n",
                        "(78100, 24)\n",
                        "(75432, 24)\n",
                        "(74211, 24)\n"
                    ]
                }
            ],
            "source": [
                "#Again checking to see how many rows and columns were in each dataframe after that step so that I can track changes in the datasets across this cleaning/manipulation process:\n",
                "print(year2024b.shape)\n",
                "print(year2023b.shape)\n",
                "print(year2022b.shape)\n",
                "print(year2021b.shape)\n",
                "print(year2020b.shape)\n",
                "print(year2019b.shape)\n",
                "print(year2018b.shape)\n",
                "print(year2017b.shape)                      \n",
                "print(year2016b.shape)\n",
                "print(year2015b.shape)\n",
                "print(year2014b.shape)\n",
                "print(year2013b.shape)\n",
                "print(year2012b.shape)                      \n",
                "print(year2011b.shape)\n",
                "\n",
                "# The output shows that after this step, this is the row/column count for each year for dataset \"b\":\n",
                "#year\ta\t            b\n",
                "#2024\t(84312, 24)\n",
                "#2023\t(83854, 24)\n",
                "#2022\t(83921, 24)\n",
                "#2021\t(83349, 24)\n",
                "#2020\t(83061, 24)\n",
                "#2019\t(82981, 24)\n",
                "#2018\t(82247, 24)\n",
                "#2017\t(81547, 24)\n",
                "#2016\t(80229, 24)\n",
                "#2015\t(80541, 24)\n",
                "#2014\t(79319, 24)\n",
                "#2013\t(78100, 24)\n",
                "#2012\t(75432, 24)\n",
                "#2011\t(74211, 24)\n",
                "\n",
                "\n",
                "#Note that the datsets from 2011-2024 now only have 24 variables/columns."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 27,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Index(['UNITID', 'CIPCODE', 'CTOTALT', 'CTOTALM', 'CTOTALW', 'CAIANT',\n",
                        "       'CAIANM', 'CAIANW', 'CBKAAT', 'CBKAAM', 'CBKAAW', 'CHISPT', 'CHISPM',\n",
                        "       'CHISPW', 'CWHITT', 'CWHITM', 'CWHITW', 'year', 'CASIAT', 'CASIAM',\n",
                        "       'CASIAW', 'CNHPIT', 'CNHPIM', 'CNHPIW'],\n",
                        "      dtype='object')\n",
                        "Index(['UNITID', 'CIPCODE', 'CTOTALT', 'CTOTALM', 'CTOTALW', 'CAIANT',\n",
                        "       'CAIANM', 'CAIANW', 'CBKAAT', 'CBKAAM', 'CBKAAW', 'CHISPT', 'CHISPM',\n",
                        "       'CHISPW', 'CWHITT', 'CWHITM', 'CWHITW', 'year', 'CASIAT', 'CASIAM',\n",
                        "       'CASIAW', 'CNHPIT', 'CNHPIM', 'CNHPIW'],\n",
                        "      dtype='object')\n",
                        "Index(['UNITID', 'CIPCODE', 'CTOTALT', 'CTOTALM', 'CTOTALW', 'CAIANT',\n",
                        "       'CAIANM', 'CAIANW', 'CBKAAT', 'CBKAAM', 'CBKAAW', 'CHISPT', 'CHISPM',\n",
                        "       'CHISPW', 'CWHITT', 'CWHITM', 'CWHITW', 'year', 'CASIAT', 'CASIAM',\n",
                        "       'CASIAW', 'CNHPIT', 'CNHPIM', 'CNHPIW'],\n",
                        "      dtype='object')\n",
                        "UNITID         0\n",
                        "CIPCODE        0\n",
                        "CTOTALT        0\n",
                        "CTOTALM        0\n",
                        "CTOTALW        0\n",
                        "CAIANT         0\n",
                        "CAIANM         0\n",
                        "CAIANW         0\n",
                        "CASIAT     69464\n",
                        "CASIAM     69464\n",
                        "CASIAW     69464\n",
                        "CBKAAT         0\n",
                        "CBKAAM         0\n",
                        "CBKAAW         0\n",
                        "CHISPT         0\n",
                        "CHISPM         0\n",
                        "CHISPW         0\n",
                        "CNHPIT     69464\n",
                        "CNHPIM     69464\n",
                        "CNHPIW     69464\n",
                        "CWHITT         0\n",
                        "CWHITM         0\n",
                        "CWHITW         0\n",
                        "year           0\n",
                        "dtype: int64\n",
                        "UNITID         0\n",
                        "CIPCODE        0\n",
                        "CTOTALT        0\n",
                        "CTOTALM        0\n",
                        "CTOTALW        0\n",
                        "CAIANT         0\n",
                        "CAIANM         0\n",
                        "CAIANW         0\n",
                        "CASIAT     71815\n",
                        "CASIAM     71815\n",
                        "CASIAW     71815\n",
                        "CBKAAT         0\n",
                        "CBKAAM         0\n",
                        "CBKAAW         0\n",
                        "CHISPT         0\n",
                        "CHISPM         0\n",
                        "CHISPW         0\n",
                        "CNHPIT     71815\n",
                        "CNHPIM     71815\n",
                        "CNHPIW     71815\n",
                        "CWHITT         0\n",
                        "CWHITM         0\n",
                        "CWHITW         0\n",
                        "year           0\n",
                        "dtype: int64\n",
                        "UNITID         0\n",
                        "CIPCODE        0\n",
                        "CTOTALT        0\n",
                        "CTOTALM        0\n",
                        "CTOTALW        0\n",
                        "CAIANT         0\n",
                        "CAIANM         0\n",
                        "CAIANW         0\n",
                        "CASIAT     73828\n",
                        "CASIAM     73828\n",
                        "CASIAW     73828\n",
                        "CBKAAT         0\n",
                        "CBKAAM         0\n",
                        "CBKAAW         0\n",
                        "CHISPT         0\n",
                        "CHISPM         0\n",
                        "CHISPW         0\n",
                        "CNHPIT     73828\n",
                        "CNHPIM     73828\n",
                        "CNHPIW     73828\n",
                        "CWHITT         0\n",
                        "CWHITM         0\n",
                        "CWHITW         0\n",
                        "year           0\n",
                        "dtype: int64\n"
                    ]
                }
            ],
            "source": [
                "#  C: INTERMEDIATE YEARS (2008-2010):  RESULTING DATAFRAMES HAVE SUFFIX \"b\".\n",
                "# \n",
                "# Before 2011, the race/ethnicity data is a little bit complicated to work with. Specifically, for each race/ethnic category, for these 3 years, institutions were \n",
                "# allowed to report race/ethnicity data from graduates based using either old categories, new categories, or a combination of the two.  Then IPEDS derived a value \n",
                "# from what was reported. The datasets contain the old, new, and derived values. Additionally, from 1989-2007, # \"Asian\" was included with Hawaiaan/Other Pacific \n",
                "# Islanders.  From 2011 on, Asians and HPIs were split apart. From 2008-2010, responding institutions could use either set of categories. Because of this lack of \n",
                "# clarity, I decided NOT to use data from Asian/HPI students before the year 2011, as I thought it would muddy interpretation. Additionally, because I want to keep\n",
                "# the derived values and use them going forward, but the \"new\" categories have the same name as the variables in 2011-2024, I needed to delete those\n",
                "# columns, then rename the derived columns with those column names. The order is very important!\n",
                "# \n",
                "# 1. Confirm what I just said by running some missing value counts. (The first printout should show lots of missing values since only some respondents used these\n",
                "# categories, but teh second printout should show no missing values b/c the researchers derived all the values from both categories' responses)\n",
                "#print(year2008[['UNITID', 'CIPCODE', 'CTOTALT', 'CTOTALM', 'CTOTALW', 'CAIANT', 'CAIANM', 'CAIANW', 'CASIAT', 'CASIAM', 'CASIAW', 'CBKAAT','CBKAAM', 'CBKAAW', 'CHISPT', 'CHISPM', 'CHISPW', 'CNHPIT', 'CNHPIM', 'CNHPIW', 'CWHITT', 'CWHITM', 'CWHITW']].isna().sum())\n",
                "#print(year2008[[\"DVCAIT\", \"DVCAIM\", \"DVCAIW\", \"DVCBKT\", \"DVCBKM\", \"DVCBKW\", \"DVCHST\", \"DVCHSM\", \"DVCHSW\", \"DVCAPT\", \"DVCAPM\", \"DVCAPW\", \"DVCWHT\", \"DVCWHM\", \"DVCWHW\"]].isna().sum())\n",
                "\n",
                "# 2. Drop the categories with the names I want to use (which have incomplete data)\n",
                "year2008b=year2008a.drop(['CAIANT', 'CAIANM', 'CAIANW', 'CBKAAT', 'CBKAAM', 'CBKAAW', 'CHISPT', 'CHISPM', 'CHISPW', 'CNHPIT', 'CNHPIM', 'CNHPIW', 'CWHITT', 'CWHITM', 'CWHITW'], axis=1)\n",
                "year2008b.head()\n",
                "\n",
                "year2009b=year2009a.drop(['CAIANT', 'CAIANM', 'CAIANW', 'CBKAAT', 'CBKAAM', 'CBKAAW', 'CHISPT', 'CHISPM', 'CHISPW', 'CNHPIT', 'CNHPIM', 'CNHPIW', 'CWHITT', 'CWHITM', 'CWHITW'], axis=1)\n",
                "year2009b.head()\n",
                "\n",
                "year2010b=year2010a.drop(['CAIANT', 'CAIANM', 'CAIANW', 'CBKAAT', 'CBKAAM', 'CBKAAW', 'CHISPT', 'CHISPM', 'CHISPW', 'CNHPIT', 'CNHPIM', 'CNHPIW', 'CWHITT', 'CWHITM', 'CWHITW'], axis=1)\n",
                "year2010b.head()\n",
                "\n",
                "# 3. then rename the columns (tried to do it in a loop, but couldn't get it to work) for the intermediate years [year2008, year2009, year2010]\n",
                "\n",
                "year2008b = year2008b.rename(columns={\"DVCAIT\":\"CAIANT\", \"DVCAIM\":\"CAIANM\", \"DVCAIW\":\"CAIANW\", \"DVCBKT\":\"CBKAAT\", \"DVCBKM\":\"CBKAAM\", \"DVCBKW\":\"CBKAAW\", \"DVCHST\":\"CHISPT\", \"DVCHSM\":\"CHISPM\", \"DVCHSW\":\"CHISPW\",\n",
                "                                 \"DVCAPT\":\"CNHPIT\", \"DVCAPM\":\"CNHPIM\", \"DVCAPW\":\"CNHPIW\", \"DVCWHT\":\"CWHITT\", \"DVCWHM\":\"CWHITM\", \"DVCWHW\":\"CWHITW\"})\n",
                "year2009b = year2009b.rename(columns={\"DVCAIT\":\"CAIANT\", \"DVCAIM\":\"CAIANM\", \"DVCAIW\":\"CAIANW\", \"DVCBKT\":\"CBKAAT\", \"DVCBKM\":\"CBKAAM\", \"DVCBKW\":\"CBKAAW\", \"DVCHST\":\"CHISPT\", \"DVCHSM\":\"CHISPM\", \"DVCHSW\":\"CHISPW\",\n",
                "                                 \"DVCAPT\":\"CNHPIT\", \"DVCAPM\":\"CNHPIM\", \"DVCAPW\":\"CNHPIW\", \"DVCWHT\":\"CWHITT\", \"DVCWHM\":\"CWHITM\", \"DVCWHW\":\"CWHITW\"})\n",
                "year2010b = year2010b.rename(columns={\"DVCAIT\":\"CAIANT\", \"DVCAIM\":\"CAIANM\", \"DVCAIW\":\"CAIANW\", \"DVCBKT\":\"CBKAAT\", \"DVCBKM\":\"CBKAAM\", \"DVCBKW\":\"CBKAAW\", \"DVCHST\":\"CHISPT\", \"DVCHSM\":\"CHISPM\", \"DVCHSW\":\"CHISPW\",\n",
                "                                 \"DVCAPT\":\"CNHPIT\", \"DVCAPM\":\"CNHPIM\", \"DVCAPW\":\"CNHPIW\", \"DVCWHT\":\"CWHITT\", \"DVCWHM\":\"CWHITM\", \"DVCWHW\":\"CWHITW\"})\n",
                "\n",
                "#4. Limit datasets to only the columns I want to keep\n",
                "columns_to_keep = ['UNITID', 'CIPCODE', 'CTOTALT', 'CTOTALM', 'CTOTALW', 'CAIANT', 'CAIANM', 'CAIANW', 'CBKAAT', 'CBKAAM','CBKAAW','CHISPT', 'CHISPM', 'CHISPW', 'CWHITT', 'CWHITM', 'CWHITW']\n",
                "\n",
                "#I tried to do the following in a loop but I couldn't get it to save the changes permanently to the dataframes...not sure why\n",
                "year2008b = year2008b[columns_to_keep]\n",
                "year2009b = year2009b[columns_to_keep]\n",
                "year2010b = year2010b[columns_to_keep]\n",
                "\n",
                "#5.  Add YEAR column to all 3 datasets\n",
                "year2008b[\"year\"] = 2008\n",
                "year2009b[\"year\"] = 2009\n",
                "year2010b[\"year\"] = 2010\n",
                "\n",
                "# 6. Add CASIAT, CASIAM, CASIAW columns and fill with NaN values so these datasets' columns match those of recent datasets (with a loop)\n",
                "year2008b[\"CASIAT\"] = np.nan\n",
                "year2008b[\"CASIAM\"] = np.nan\n",
                "year2008b[\"CASIAW\"] = np.nan\n",
                "year2008b[\"CNHPIT\"] = np.nan\n",
                "year2008b[\"CNHPIM\"] = np.nan\n",
                "year2008b[\"CNHPIW\"] = np.nan\n",
                "\n",
                "year2009b[\"CASIAT\"] = np.nan\n",
                "year2009b[\"CASIAM\"] = np.nan\n",
                "year2009b[\"CASIAW\"] = np.nan\n",
                "year2009b[\"CNHPIT\"] = np.nan\n",
                "year2009b[\"CNHPIM\"] = np.nan\n",
                "year2009b[\"CNHPIW\"] = np.nan\n",
                "\n",
                "year2010b[\"CASIAT\"] = np.nan\n",
                "year2010b[\"CASIAM\"] = np.nan\n",
                "year2010b[\"CASIAW\"] = np.nan\n",
                "year2010b[\"CNHPIT\"] = np.nan\n",
                "year2010b[\"CNHPIM\"] = np.nan\n",
                "year2010b[\"CNHPIW\"] = np.nan\n",
                "\n",
                "#and just to make sure everything worked.....\n",
                "print(year2008b.columns)\n",
                "print(year2009b.columns)\n",
                "print(year2010b.columns)\n",
                "\n",
                "# 7. Check for missing values\n",
                "print(year2008b[['UNITID', 'CIPCODE', 'CTOTALT', 'CTOTALM', 'CTOTALW', 'CAIANT', 'CAIANM', 'CAIANW', 'CASIAT', 'CASIAM', 'CASIAW', 'CBKAAT', 'CBKAAM', 'CBKAAW', 'CHISPT', 'CHISPM', 'CHISPW', 'CNHPIT', 'CNHPIM', 'CNHPIW', 'CWHITT', 'CWHITM', 'CWHITW', 'year']].isna().sum())\n",
                "print(year2009b[['UNITID', 'CIPCODE', 'CTOTALT', 'CTOTALM', 'CTOTALW', 'CAIANT', 'CAIANM', 'CAIANW', 'CASIAT', 'CASIAM', 'CASIAW', 'CBKAAT', 'CBKAAM', 'CBKAAW', 'CHISPT', 'CHISPM', 'CHISPW', 'CNHPIT', 'CNHPIM', 'CNHPIW', 'CWHITT', 'CWHITM', 'CWHITW', 'year']].isna().sum())\n",
                "print(year2010b[['UNITID', 'CIPCODE', 'CTOTALT', 'CTOTALM', 'CTOTALW', 'CAIANT', 'CAIANM', 'CAIANW', 'CASIAT', 'CASIAM', 'CASIAW', 'CBKAAT', 'CBKAAM', 'CBKAAW', 'CHISPT', 'CHISPM', 'CHISPW', 'CNHPIT', 'CNHPIM', 'CNHPIW', 'CWHITT', 'CWHITM', 'CWHITW', 'year']].isna().sum())\n",
                "\n",
                "# The only missing values are those for Asian and HPI, which is correct!"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "(69464, 24)\n",
                        "(71815, 24)\n",
                        "(73828, 24)\n"
                    ]
                }
            ],
            "source": [
                "#Again checking to see how many rows and columns were in each dataframe after that step so that I can track changes in the datasets across this cleaning/manipulation process:\n",
                "print(year2008b.shape)\n",
                "print(year2009b.shape)\n",
                "print(year2010b.shape)\n",
                "\n",
                "#and we have the same # of rows as before, but 24 columns as desired:\n",
                "# 2010\t(73828, 24)\n",
                "# 2009\t(71815, 24)\n",
                "# 2008\t(69464, 24)\n",
                "\n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 30,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Index(['UNITID', 'CIPCODE', 'CTOTALM', 'CTOTALW', 'CAIANM', 'CAIANW', 'CBKAAM',\n",
                        "       'CBKAAW', 'CHISPM', 'CHISPW', 'CWHITM', 'CWHITW', 'year', 'CTOTALT',\n",
                        "       'CAIANT', 'CBKAAT', 'CHISPT', 'CWHITT', 'CASIAT', 'CASIAM', 'CASIAW',\n",
                        "       'CNHPIT', 'CNHPIM', 'CNHPIW'],\n",
                        "      dtype='object')\n",
                        "UNITID         0\n",
                        "CIPCODE        0\n",
                        "CTOTALT        0\n",
                        "CTOTALM        0\n",
                        "CTOTALW        0\n",
                        "CAIANT         0\n",
                        "CAIANM         0\n",
                        "CAIANW         0\n",
                        "CASIAT     53191\n",
                        "CASIAM     53191\n",
                        "CASIAW     53191\n",
                        "CBKAAT         0\n",
                        "CBKAAM         0\n",
                        "CBKAAW         0\n",
                        "CHISPT         0\n",
                        "CHISPM         0\n",
                        "CHISPW         0\n",
                        "CNHPIT     53191\n",
                        "CNHPIM     53191\n",
                        "CNHPIW     53191\n",
                        "CWHITT         0\n",
                        "CWHITM         0\n",
                        "CWHITW         0\n",
                        "year           0\n",
                        "dtype: int64\n",
                        "UNITID         0\n",
                        "CIPCODE        0\n",
                        "CTOTALT        0\n",
                        "CTOTALM        0\n",
                        "CTOTALW        0\n",
                        "CAIANT         0\n",
                        "CAIANM         0\n",
                        "CAIANW         0\n",
                        "CASIAT     53460\n",
                        "CASIAM     53460\n",
                        "CASIAW     53460\n",
                        "CBKAAT         0\n",
                        "CBKAAM         0\n",
                        "CBKAAW         0\n",
                        "CHISPT         0\n",
                        "CHISPM         0\n",
                        "CHISPW         0\n",
                        "CNHPIT     53460\n",
                        "CNHPIM     53460\n",
                        "CNHPIW     53460\n",
                        "CWHITT         0\n",
                        "CWHITM         0\n",
                        "CWHITW         0\n",
                        "year           0\n",
                        "dtype: int64\n",
                        "UNITID         0\n",
                        "CIPCODE        0\n",
                        "CTOTALT        0\n",
                        "CTOTALM        0\n",
                        "CTOTALW        0\n",
                        "CAIANT         0\n",
                        "CAIANM         0\n",
                        "CAIANW         0\n",
                        "CASIAT     58298\n",
                        "CASIAM     58298\n",
                        "CASIAW     58298\n",
                        "CBKAAT         0\n",
                        "CBKAAM         0\n",
                        "CBKAAW         0\n",
                        "CHISPT         0\n",
                        "CHISPM         0\n",
                        "CHISPW         0\n",
                        "CNHPIT     58298\n",
                        "CNHPIM     58298\n",
                        "CNHPIW     58298\n",
                        "CWHITT         0\n",
                        "CWHITM         0\n",
                        "CWHITW         0\n",
                        "year           0\n",
                        "dtype: int64\n",
                        "UNITID         0\n",
                        "CIPCODE        0\n",
                        "CTOTALT        0\n",
                        "CTOTALM        0\n",
                        "CTOTALW        0\n",
                        "CAIANT         0\n",
                        "CAIANM         0\n",
                        "CAIANW         0\n",
                        "CASIAT     52525\n",
                        "CASIAM     52525\n",
                        "CASIAW     52525\n",
                        "CBKAAT         0\n",
                        "CBKAAM         0\n",
                        "CBKAAW         0\n",
                        "CHISPT         0\n",
                        "CHISPM         0\n",
                        "CHISPW         0\n",
                        "CNHPIT     52525\n",
                        "CNHPIM     52525\n",
                        "CNHPIW     52525\n",
                        "CWHITT         0\n",
                        "CWHITM         0\n",
                        "CWHITW         0\n",
                        "year           0\n",
                        "dtype: int64\n",
                        "UNITID         0\n",
                        "CIPCODE        0\n",
                        "CTOTALT        0\n",
                        "CTOTALM        0\n",
                        "CTOTALW        0\n",
                        "CAIANT         0\n",
                        "CAIANM         0\n",
                        "CAIANW         0\n",
                        "CASIAT     58189\n",
                        "CASIAM     58189\n",
                        "CASIAW     58189\n",
                        "CBKAAT         0\n",
                        "CBKAAM         0\n",
                        "CBKAAW         0\n",
                        "CHISPT         0\n",
                        "CHISPM         0\n",
                        "CHISPW         0\n",
                        "CNHPIT     58189\n",
                        "CNHPIM     58189\n",
                        "CNHPIW     58189\n",
                        "CWHITT         0\n",
                        "CWHITM         0\n",
                        "CWHITW         0\n",
                        "year           0\n",
                        "dtype: int64\n",
                        "UNITID         0\n",
                        "CIPCODE        0\n",
                        "CTOTALT        0\n",
                        "CTOTALM        0\n",
                        "CTOTALW        0\n",
                        "CAIANT         0\n",
                        "CAIANM         0\n",
                        "CAIANW         0\n",
                        "CASIAT     59959\n",
                        "CASIAM     59959\n",
                        "CASIAW     59959\n",
                        "CBKAAT         0\n",
                        "CBKAAM         0\n",
                        "CBKAAW         0\n",
                        "CHISPT         0\n",
                        "CHISPM         0\n",
                        "CHISPW         0\n",
                        "CNHPIT     59959\n",
                        "CNHPIM     59959\n",
                        "CNHPIW     59959\n",
                        "CWHITT         0\n",
                        "CWHITM         0\n",
                        "CWHITW         0\n",
                        "year           0\n",
                        "dtype: int64\n",
                        "UNITID         0\n",
                        "CIPCODE        0\n",
                        "CTOTALT        0\n",
                        "CTOTALM        0\n",
                        "CTOTALW        0\n",
                        "CAIANT         0\n",
                        "CAIANM         0\n",
                        "CAIANW         0\n",
                        "CASIAT     60267\n",
                        "CASIAM     60267\n",
                        "CASIAW     60267\n",
                        "CBKAAT         0\n",
                        "CBKAAM         0\n",
                        "CBKAAW         0\n",
                        "CHISPT         0\n",
                        "CHISPM         0\n",
                        "CHISPW         0\n",
                        "CNHPIT     60267\n",
                        "CNHPIM     60267\n",
                        "CNHPIW     60267\n",
                        "CWHITT         0\n",
                        "CWHITM         0\n",
                        "CWHITW         0\n",
                        "year           0\n",
                        "dtype: int64\n",
                        "UNITID         0\n",
                        "CIPCODE        0\n",
                        "CTOTALT        0\n",
                        "CTOTALM        0\n",
                        "CTOTALW        0\n",
                        "CAIANT         0\n",
                        "CAIANM         0\n",
                        "CAIANW         0\n",
                        "CASIAT     62059\n",
                        "CASIAM     62059\n",
                        "CASIAW     62059\n",
                        "CBKAAT         0\n",
                        "CBKAAM         0\n",
                        "CBKAAW         0\n",
                        "CHISPT         0\n",
                        "CHISPM         0\n",
                        "CHISPW         0\n",
                        "CNHPIT     62059\n",
                        "CNHPIM     62059\n",
                        "CNHPIW     62059\n",
                        "CWHITT         0\n",
                        "CWHITM         0\n",
                        "CWHITW         0\n",
                        "year           0\n",
                        "dtype: int64\n",
                        "UNITID         0\n",
                        "CIPCODE        0\n",
                        "CTOTALT        0\n",
                        "CTOTALM        0\n",
                        "CTOTALW        0\n",
                        "CAIANT         0\n",
                        "CAIANM         0\n",
                        "CAIANW         0\n",
                        "CASIAT     63905\n",
                        "CASIAM     63905\n",
                        "CASIAW     63905\n",
                        "CBKAAT         0\n",
                        "CBKAAM         0\n",
                        "CBKAAW         0\n",
                        "CHISPT         0\n",
                        "CHISPM         0\n",
                        "CHISPW         0\n",
                        "CNHPIT     63905\n",
                        "CNHPIM     63905\n",
                        "CNHPIW     63905\n",
                        "CWHITT         0\n",
                        "CWHITM         0\n",
                        "CWHITW         0\n",
                        "year           0\n",
                        "dtype: int64\n",
                        "UNITID         0\n",
                        "CIPCODE        0\n",
                        "CTOTALT        0\n",
                        "CTOTALM        0\n",
                        "CTOTALW        0\n",
                        "CAIANT         0\n",
                        "CAIANM         0\n",
                        "CAIANW         0\n",
                        "CASIAT     66018\n",
                        "CASIAM     66018\n",
                        "CASIAW     66018\n",
                        "CBKAAT         0\n",
                        "CBKAAM         0\n",
                        "CBKAAW         0\n",
                        "CHISPT         0\n",
                        "CHISPM         0\n",
                        "CHISPW         0\n",
                        "CNHPIT     66018\n",
                        "CNHPIM     66018\n",
                        "CNHPIW     66018\n",
                        "CWHITT         0\n",
                        "CWHITM         0\n",
                        "CWHITW         0\n",
                        "year           0\n",
                        "dtype: int64\n",
                        "UNITID         0\n",
                        "CIPCODE        0\n",
                        "CTOTALT        0\n",
                        "CTOTALM        0\n",
                        "CTOTALW        0\n",
                        "CAIANT         0\n",
                        "CAIANM         0\n",
                        "CAIANW         0\n",
                        "CASIAT     67578\n",
                        "CASIAM     67578\n",
                        "CASIAW     67578\n",
                        "CBKAAT         0\n",
                        "CBKAAM         0\n",
                        "CBKAAW         0\n",
                        "CHISPT         0\n",
                        "CHISPM         0\n",
                        "CHISPW         0\n",
                        "CNHPIT     67578\n",
                        "CNHPIM     67578\n",
                        "CNHPIW     67578\n",
                        "CWHITT         0\n",
                        "CWHITM         0\n",
                        "CWHITW         0\n",
                        "year           0\n",
                        "dtype: int64\n",
                        "UNITID         0\n",
                        "CIPCODE        0\n",
                        "CTOTALT        0\n",
                        "CTOTALM        0\n",
                        "CTOTALW        0\n",
                        "CAIANT         0\n",
                        "CAIANM         0\n",
                        "CAIANW         0\n",
                        "CASIAT     68646\n",
                        "CASIAM     68646\n",
                        "CASIAW     68646\n",
                        "CBKAAT         0\n",
                        "CBKAAM         0\n",
                        "CBKAAW         0\n",
                        "CHISPT         0\n",
                        "CHISPM         0\n",
                        "CHISPW         0\n",
                        "CNHPIT     68646\n",
                        "CNHPIM     68646\n",
                        "CNHPIW     68646\n",
                        "CWHITT         0\n",
                        "CWHITM         0\n",
                        "CWHITW         0\n",
                        "year           0\n",
                        "dtype: int64\n"
                    ]
                }
            ],
            "source": [
                "#   D: OLD DATASETS (1996-2007): Make this dataset have same columns as recent datasets:  RESULTING DATAFRAMES HAVE SUFFIX \"b\".\n",
                "# \n",
                "# 1. Change column names from oldest datasets to match the names of those columns in recent datasets AND create \"total\" columns \n",
                "\n",
                "year1996b = year1996a.rename(columns={\"CRACE15\":\"CTOTALM\", \"CRACE16\":\"CTOTALW\", \"CRACE05\":\"CAIANM\", \"CRACE06\":\"CAIANW\", \"CRACE03\":\"CBKAAM\", \"CRACE04\":\"CBKAAW\", \"CRACE09\":\"CHISPM\", \n",
                "                     \"CRACE10\":\"CHISPW\", \"CRACE07\":\"CNHPIM\", \"CRACE08\":\"CNHPIW\", \"CRACE11\":\"CWHITM\", \"CRACE12\":\"CWHITW\", \"CRACE01\":\"CNRALM\", \"CRACE02\":\"CNRALW\"})\n",
                "year1997b = year1997a.rename(columns={\"CRACE15\":\"CTOTALM\", \"CRACE16\":\"CTOTALW\", \"CRACE05\":\"CAIANM\", \"CRACE06\":\"CAIANW\", \"CRACE03\":\"CBKAAM\", \"CRACE04\":\"CBKAAW\", \"CRACE09\":\"CHISPM\", \n",
                "                     \"CRACE10\":\"CHISPW\", \"CRACE07\":\"CNHPIM\", \"CRACE08\":\"CNHPIW\", \"CRACE11\":\"CWHITM\", \"CRACE12\":\"CWHITW\", \"CRACE01\":\"CNRALM\", \"CRACE02\":\"CNRALW\"})\n",
                "year1998b = year1998a.rename(columns={\"CRACE15\":\"CTOTALM\", \"CRACE16\":\"CTOTALW\", \"CRACE05\":\"CAIANM\", \"CRACE06\":\"CAIANW\", \"CRACE03\":\"CBKAAM\", \"CRACE04\":\"CBKAAW\", \"CRACE09\":\"CHISPM\", \n",
                "                     \"CRACE10\":\"CHISPW\", \"CRACE07\":\"CNHPIM\", \"CRACE08\":\"CNHPIW\", \"CRACE11\":\"CWHITM\", \"CRACE12\":\"CWHITW\", \"CRACE01\":\"CNRALM\", \"CRACE02\":\"CNRALW\"})\n",
                "year1999b = year1999a.rename(columns={\"CRACE15\":\"CTOTALM\", \"CRACE16\":\"CTOTALW\", \"CRACE05\":\"CAIANM\", \"CRACE06\":\"CAIANW\", \"CRACE03\":\"CBKAAM\", \"CRACE04\":\"CBKAAW\", \"CRACE09\":\"CHISPM\", \n",
                "                     \"CRACE10\":\"CHISPW\", \"CRACE07\":\"CNHPIM\", \"CRACE08\":\"CNHPIW\", \"CRACE11\":\"CWHITM\", \"CRACE12\":\"CWHITW\", \"CRACE01\":\"CNRALM\", \"CRACE02\":\"CNRALW\"})\n",
                "year2000b = year2000a.rename(columns={\"CRACE15\":\"CTOTALM\", \"CRACE16\":\"CTOTALW\", \"CRACE05\":\"CAIANM\", \"CRACE06\":\"CAIANW\", \"CRACE03\":\"CBKAAM\", \"CRACE04\":\"CBKAAW\", \"CRACE09\":\"CHISPM\", \n",
                "                     \"CRACE10\":\"CHISPW\", \"CRACE07\":\"CNHPIM\", \"CRACE08\":\"CNHPIW\", \"CRACE11\":\"CWHITM\", \"CRACE12\":\"CWHITW\", \"CRACE01\":\"CNRALM\", \"CRACE02\":\"CNRALW\"})\n",
                "year2001b = year2001a.rename(columns={\"CRACE15\":\"CTOTALM\", \"CRACE16\":\"CTOTALW\", \"CRACE05\":\"CAIANM\", \"CRACE06\":\"CAIANW\", \"CRACE03\":\"CBKAAM\", \"CRACE04\":\"CBKAAW\", \"CRACE09\":\"CHISPM\", \n",
                "                     \"CRACE10\":\"CHISPW\", \"CRACE07\":\"CNHPIM\", \"CRACE08\":\"CNHPIW\", \"CRACE11\":\"CWHITM\", \"CRACE12\":\"CWHITW\", \"CRACE01\":\"CNRALM\", \"CRACE02\":\"CNRALW\"})\n",
                "year2002b = year2002a.rename(columns={\"CRACE15\":\"CTOTALM\", \"CRACE16\":\"CTOTALW\", \"CRACE05\":\"CAIANM\", \"CRACE06\":\"CAIANW\", \"CRACE03\":\"CBKAAM\", \"CRACE04\":\"CBKAAW\", \"CRACE09\":\"CHISPM\", \n",
                "                     \"CRACE10\":\"CHISPW\", \"CRACE07\":\"CNHPIM\", \"CRACE08\":\"CNHPIW\", \"CRACE11\":\"CWHITM\", \"CRACE12\":\"CWHITW\", \"CRACE01\":\"CNRALM\", \"CRACE02\":\"CNRALW\"})\n",
                "year2003b = year2003a.rename(columns={\"CRACE15\":\"CTOTALM\", \"CRACE16\":\"CTOTALW\", \"CRACE05\":\"CAIANM\", \"CRACE06\":\"CAIANW\", \"CRACE03\":\"CBKAAM\", \"CRACE04\":\"CBKAAW\", \"CRACE09\":\"CHISPM\", \n",
                "                     \"CRACE10\":\"CHISPW\", \"CRACE07\":\"CNHPIM\", \"CRACE08\":\"CNHPIW\", \"CRACE11\":\"CWHITM\", \"CRACE12\":\"CWHITW\", \"CRACE01\":\"CNRALM\", \"CRACE02\":\"CNRALW\"})\n",
                "year2004b = year2004a.rename(columns={\"CRACE15\":\"CTOTALM\", \"CRACE16\":\"CTOTALW\", \"CRACE05\":\"CAIANM\", \"CRACE06\":\"CAIANW\", \"CRACE03\":\"CBKAAM\", \"CRACE04\":\"CBKAAW\", \"CRACE09\":\"CHISPM\", \n",
                "                     \"CRACE10\":\"CHISPW\", \"CRACE07\":\"CNHPIM\", \"CRACE08\":\"CNHPIW\", \"CRACE11\":\"CWHITM\", \"CRACE12\":\"CWHITW\", \"CRACE01\":\"CNRALM\", \"CRACE02\":\"CNRALW\"})\n",
                "year2005b = year2005a.rename(columns={\"CRACE15\":\"CTOTALM\", \"CRACE16\":\"CTOTALW\", \"CRACE05\":\"CAIANM\", \"CRACE06\":\"CAIANW\", \"CRACE03\":\"CBKAAM\", \"CRACE04\":\"CBKAAW\", \"CRACE09\":\"CHISPM\", \n",
                "                     \"CRACE10\":\"CHISPW\", \"CRACE07\":\"CNHPIM\", \"CRACE08\":\"CNHPIW\", \"CRACE11\":\"CWHITM\", \"CRACE12\":\"CWHITW\", \"CRACE01\":\"CNRALM\", \"CRACE02\":\"CNRALW\"})\n",
                "year2006b = year2006a.rename(columns={\"CRACE15\":\"CTOTALM\", \"CRACE16\":\"CTOTALW\", \"CRACE05\":\"CAIANM\", \"CRACE06\":\"CAIANW\", \"CRACE03\":\"CBKAAM\", \"CRACE04\":\"CBKAAW\", \"CRACE09\":\"CHISPM\", \n",
                "                     \"CRACE10\":\"CHISPW\", \"CRACE07\":\"CNHPIM\", \"CRACE08\":\"CNHPIW\", \"CRACE11\":\"CWHITM\", \"CRACE12\":\"CWHITW\", \"CRACE01\":\"CNRALM\", \"CRACE02\":\"CNRALW\"})\n",
                "year2007b = year2007a.rename(columns={\"CRACE15\":\"CTOTALM\", \"CRACE16\":\"CTOTALW\", \"CRACE05\":\"CAIANM\", \"CRACE06\":\"CAIANW\", \"CRACE03\":\"CBKAAM\", \"CRACE04\":\"CBKAAW\", \"CRACE09\":\"CHISPM\", \n",
                "                     \"CRACE10\":\"CHISPW\", \"CRACE07\":\"CNHPIM\", \"CRACE08\":\"CNHPIW\", \"CRACE11\":\"CWHITM\", \"CRACE12\":\"CWHITW\", \"CRACE01\":\"CNRALM\", \"CRACE02\":\"CNRALW\"})\n",
                "\n",
                "# 2. Limit to only the columns I wish to keep\n",
                "columns_to_keep = ['UNITID', 'CIPCODE', 'CTOTALM', 'CTOTALW', 'CAIANM', 'CAIANW', 'CBKAAM','CBKAAW', 'CHISPM', 'CHISPW', 'CWHITM', 'CWHITW']\n",
                "year1996b = year1996b[columns_to_keep]\n",
                "year1997b = year1997b[columns_to_keep]\n",
                "year1998b = year1998b[columns_to_keep]\n",
                "year1999b = year1999b[columns_to_keep]\n",
                "year2000b = year2000b[columns_to_keep]\n",
                "year2001b = year2001b[columns_to_keep]\n",
                "year2002b = year2002b[columns_to_keep]\n",
                "year2003b = year2003b[columns_to_keep]\n",
                "year2004b = year2004b[columns_to_keep]\n",
                "year2005b = year2005b[columns_to_keep]\n",
                "year2006b = year2006b[columns_to_keep]\n",
                "year2007b = year2007b[columns_to_keep]\n",
                "\n",
                "# 3: ADD \"YEAR\" COLUMN TO EACH DATASET SO THAT I CAN TELL THEM APART WHEN I MERGE THEM\n",
                "year1996b[\"year\"] = 1996\n",
                "year1997b[\"year\"] = 1997\n",
                "year1998b[\"year\"] = 1998\n",
                "year1999b[\"year\"] = 1999\n",
                "year2000b[\"year\"] = 2000\n",
                "year2001b[\"year\"] = 2001\n",
                "year2002b[\"year\"] = 2002\n",
                "year2003b[\"year\"] = 2003\n",
                "year2004b[\"year\"] = 2004\n",
                "year2005b[\"year\"] = 2005\n",
                "year2006b[\"year\"] = 2006\n",
                "year2007b[\"year\"] = 2007\n",
                "\n",
                "# 4. create total columns from \"men\" and \"women\" columns for each race/ethnic group (these don't exist in these early datasets)\n",
                "year2007b[\"CTOTALT\"] = year2007b[\"CTOTALM\"] + year2007b[\"CTOTALW\"] \n",
                "year2007b[\"CAIANT\"] = year2007b[\"CAIANM\"] + year2007b[\"CAIANW\"]\n",
                "year2007b[\"CBKAAT\"] = year2007b[\"CBKAAM\"] + year2007b[\"CBKAAW\"]\n",
                "year2007b[\"CHISPT\"] = year2007b[\"CHISPM\"] + year2007b[\"CHISPW\"]\n",
                "year2007b[\"CWHITT\"] = year2007b[\"CWHITM\"] + year2007b[\"CWHITW\"]\n",
                "\n",
                "year2006b[\"CTOTALT\"] = year2006b[\"CTOTALM\"] + year2006b[\"CTOTALW\"] \n",
                "year2006b[\"CAIANT\"] = year2006b[\"CAIANM\"] + year2006b[\"CAIANW\"]\n",
                "year2006b[\"CBKAAT\"] = year2006b[\"CBKAAM\"] + year2006b[\"CBKAAW\"]\n",
                "year2006b[\"CHISPT\"] = year2006b[\"CHISPM\"] + year2006b[\"CHISPW\"]\n",
                "year2006b[\"CWHITT\"] = year2006b[\"CWHITM\"] + year2006b[\"CWHITW\"]\n",
                "\n",
                "year2005b[\"CTOTALT\"] = year2005b[\"CTOTALM\"] + year2005b[\"CTOTALW\"] \n",
                "year2005b[\"CAIANT\"] = year2005b[\"CAIANM\"] + year2005b[\"CAIANW\"]\n",
                "year2005b[\"CBKAAT\"] = year2005b[\"CBKAAM\"] + year2005b[\"CBKAAW\"]\n",
                "year2005b[\"CHISPT\"] = year2005b[\"CHISPM\"] + year2005b[\"CHISPW\"]\n",
                "year2005b[\"CWHITT\"] = year2005b[\"CWHITM\"] + year2005b[\"CWHITW\"]\n",
                "\n",
                "year2004b[\"CTOTALT\"] = year2004b[\"CTOTALM\"] + year2004b[\"CTOTALW\"] \n",
                "year2004b[\"CAIANT\"] = year2004b[\"CAIANM\"] + year2004b[\"CAIANW\"]\n",
                "year2004b[\"CBKAAT\"] = year2004b[\"CBKAAM\"] + year2004b[\"CBKAAW\"]\n",
                "year2004b[\"CHISPT\"] = year2004b[\"CHISPM\"] + year2004b[\"CHISPW\"]\n",
                "year2004b[\"CWHITT\"] = year2004b[\"CWHITM\"] + year2004b[\"CWHITW\"]\n",
                "\n",
                "year2003b[\"CTOTALT\"] = year2003b[\"CTOTALM\"] + year2003b[\"CTOTALW\"] \n",
                "year2003b[\"CAIANT\"] = year2003b[\"CAIANM\"] + year2003b[\"CAIANW\"]\n",
                "year2003b[\"CBKAAT\"] = year2003b[\"CBKAAM\"] + year2003b[\"CBKAAW\"]\n",
                "year2003b[\"CHISPT\"] = year2003b[\"CHISPM\"] + year2003b[\"CHISPW\"]\n",
                "year2003b[\"CWHITT\"] = year2003b[\"CWHITM\"] + year2003b[\"CWHITW\"]\n",
                "\n",
                "year2002b[\"CTOTALT\"] = year2002b[\"CTOTALM\"] + year2002b[\"CTOTALW\"] \n",
                "year2002b[\"CAIANT\"] = year2002b[\"CAIANM\"] + year2002b[\"CAIANW\"]\n",
                "year2002b[\"CBKAAT\"] = year2002b[\"CBKAAM\"] + year2002b[\"CBKAAW\"]\n",
                "year2002b[\"CHISPT\"] = year2002b[\"CHISPM\"] + year2002b[\"CHISPW\"]\n",
                "year2002b[\"CWHITT\"] = year2002b[\"CWHITM\"] + year2002b[\"CWHITW\"]\n",
                "\n",
                "year2001b[\"CTOTALT\"] = year2001b[\"CTOTALM\"] + year2001b[\"CTOTALW\"] \n",
                "year2001b[\"CAIANT\"] = year2001b[\"CAIANM\"] + year2001b[\"CAIANW\"]\n",
                "year2001b[\"CBKAAT\"] = year2001b[\"CBKAAM\"] + year2001b[\"CBKAAW\"]\n",
                "year2001b[\"CHISPT\"] = year2001b[\"CHISPM\"] + year2001b[\"CHISPW\"]\n",
                "year2001b[\"CWHITT\"] = year2001b[\"CWHITM\"] + year2001b[\"CWHITW\"]\n",
                "\n",
                "year2000b[\"CTOTALT\"] = year2000b[\"CTOTALM\"] + year2000b[\"CTOTALW\"] \n",
                "year2000b[\"CAIANT\"] = year2000b[\"CAIANM\"] + year2000b[\"CAIANW\"]\n",
                "year2000b[\"CBKAAT\"] = year2000b[\"CBKAAM\"] + year2000b[\"CBKAAW\"]\n",
                "year2000b[\"CHISPT\"] = year2000b[\"CHISPM\"] + year2000b[\"CHISPW\"]\n",
                "year2000b[\"CWHITT\"] = year2000b[\"CWHITM\"] + year2000b[\"CWHITW\"]\n",
                "\n",
                "year1999b[\"CTOTALT\"] = year1999b[\"CTOTALM\"] + year1999b[\"CTOTALW\"] \n",
                "year1999b[\"CAIANT\"] = year1999b[\"CAIANM\"] + year1999b[\"CAIANW\"]\n",
                "year1999b[\"CBKAAT\"] = year1999b[\"CBKAAM\"] + year1999b[\"CBKAAW\"]\n",
                "year1999b[\"CHISPT\"] = year1999b[\"CHISPM\"] + year1999b[\"CHISPW\"]\n",
                "year1999b[\"CWHITT\"] = year1999b[\"CWHITM\"] + year1999b[\"CWHITW\"]\n",
                "\n",
                "year1998b[\"CTOTALT\"] = year1998b[\"CTOTALM\"] + year1998b[\"CTOTALW\"] \n",
                "year1998b[\"CAIANT\"] = year1998b[\"CAIANM\"] + year1998b[\"CAIANW\"]\n",
                "year1998b[\"CBKAAT\"] = year1998b[\"CBKAAM\"] + year1998b[\"CBKAAW\"]\n",
                "year1998b[\"CHISPT\"] = year1998b[\"CHISPM\"] + year1998b[\"CHISPW\"]\n",
                "year1998b[\"CWHITT\"] = year1998b[\"CWHITM\"] + year1998b[\"CWHITW\"]\n",
                "\n",
                "year1997b[\"CTOTALT\"] = year1997b[\"CTOTALM\"] + year1997b[\"CTOTALW\"] \n",
                "year1997b[\"CAIANT\"] = year1997b[\"CAIANM\"] + year1997b[\"CAIANW\"]\n",
                "year1997b[\"CBKAAT\"] = year1997b[\"CBKAAM\"] + year1997b[\"CBKAAW\"]\n",
                "year1997b[\"CHISPT\"] = year1997b[\"CHISPM\"] + year1997b[\"CHISPW\"]\n",
                "year1997b[\"CWHITT\"] = year1997b[\"CWHITM\"] + year1997b[\"CWHITW\"]\n",
                "\n",
                "year1996b[\"CTOTALT\"] = year1996b[\"CTOTALM\"] + year1996b[\"CTOTALW\"] \n",
                "year1996b[\"CAIANT\"] = year1996b[\"CAIANM\"] + year1996b[\"CAIANW\"]\n",
                "year1996b[\"CBKAAT\"] = year1996b[\"CBKAAM\"] + year1996b[\"CBKAAW\"]\n",
                "year1996b[\"CHISPT\"] = year1996b[\"CHISPM\"] + year1996b[\"CHISPW\"]\n",
                "year1996b[\"CWHITT\"] = year1996b[\"CWHITM\"] + year1996b[\"CWHITW\"]\n",
                "\n",
                "\n",
                "\n",
                "# 5. Add CASIAT, CASIAM, CASIAW columns and fill with NaN values so these datasets' columns match those of recent datasets (with a loop)\n",
                "year2007b[\"CASIAT\"] = np.nan\n",
                "year2007b[\"CASIAM\"] = np.nan\n",
                "year2007b[\"CASIAW\"] = np.nan\n",
                "year2007b[\"CNHPIT\"] = np.nan\n",
                "year2007b[\"CNHPIM\"] = np.nan\n",
                "year2007b[\"CNHPIW\"] = np.nan\n",
                "\n",
                "year2006b[\"CASIAT\"] = np.nan\n",
                "year2006b[\"CASIAM\"] = np.nan\n",
                "year2006b[\"CASIAW\"] = np.nan\n",
                "year2006b[\"CNHPIT\"] = np.nan\n",
                "year2006b[\"CNHPIM\"] = np.nan\n",
                "year2006b[\"CNHPIW\"] = np.nan\n",
                "\n",
                "year2005b[\"CASIAT\"] = np.nan\n",
                "year2005b[\"CASIAM\"] = np.nan\n",
                "year2005b[\"CASIAW\"] = np.nan\n",
                "year2005b[\"CNHPIT\"] = np.nan\n",
                "year2005b[\"CNHPIM\"] = np.nan\n",
                "year2005b[\"CNHPIW\"] = np.nan\n",
                "\n",
                "year2004b[\"CASIAT\"] = np.nan\n",
                "year2004b[\"CASIAM\"] = np.nan\n",
                "year2004b[\"CASIAW\"] = np.nan\n",
                "year2004b[\"CNHPIT\"] = np.nan\n",
                "year2004b[\"CNHPIM\"] = np.nan\n",
                "year2004b[\"CNHPIW\"] = np.nan\n",
                "\n",
                "year2003b[\"CASIAT\"] = np.nan\n",
                "year2003b[\"CASIAM\"] = np.nan\n",
                "year2003b[\"CASIAW\"] = np.nan\n",
                "year2003b[\"CNHPIT\"] = np.nan\n",
                "year2003b[\"CNHPIM\"] = np.nan\n",
                "year2003b[\"CNHPIW\"] = np.nan\n",
                "\n",
                "year2002b[\"CASIAT\"] = np.nan\n",
                "year2002b[\"CASIAM\"] = np.nan\n",
                "year2002b[\"CASIAW\"] = np.nan\n",
                "year2002b[\"CNHPIT\"] = np.nan\n",
                "year2002b[\"CNHPIM\"] = np.nan\n",
                "year2002b[\"CNHPIW\"] = np.nan\n",
                "\n",
                "year2001b[\"CASIAT\"] = np.nan\n",
                "year2001b[\"CASIAM\"] = np.nan\n",
                "year2001b[\"CASIAW\"] = np.nan\n",
                "year2001b[\"CNHPIT\"] = np.nan\n",
                "year2001b[\"CNHPIM\"] = np.nan\n",
                "year2001b[\"CNHPIW\"] = np.nan\n",
                "\n",
                "year2000b[\"CASIAT\"] = np.nan\n",
                "year2000b[\"CASIAM\"] = np.nan\n",
                "year2000b[\"CASIAW\"] = np.nan\n",
                "year2000b[\"CNHPIT\"] = np.nan\n",
                "year2000b[\"CNHPIM\"] = np.nan\n",
                "year2000b[\"CNHPIW\"] = np.nan\n",
                "\n",
                "year1999b[\"CASIAT\"] = np.nan\n",
                "year1999b[\"CASIAM\"] = np.nan\n",
                "year1999b[\"CASIAW\"] = np.nan\n",
                "year1999b[\"CNHPIT\"] = np.nan\n",
                "year1999b[\"CNHPIM\"] = np.nan\n",
                "year1999b[\"CNHPIW\"] = np.nan\n",
                "\n",
                "year1998b[\"CASIAT\"] = np.nan\n",
                "year1998b[\"CASIAM\"] = np.nan\n",
                "year1998b[\"CASIAW\"] = np.nan\n",
                "year1998b[\"CNHPIT\"] = np.nan\n",
                "year1998b[\"CNHPIM\"] = np.nan\n",
                "year1998b[\"CNHPIW\"] = np.nan\n",
                "\n",
                "year1997b[\"CASIAT\"] = np.nan\n",
                "year1997b[\"CASIAM\"] = np.nan\n",
                "year1997b[\"CASIAW\"] = np.nan\n",
                "year1997b[\"CNHPIT\"] = np.nan\n",
                "year1997b[\"CNHPIM\"] = np.nan\n",
                "year1997b[\"CNHPIW\"] = np.nan\n",
                "\n",
                "year1996b[\"CASIAT\"] = np.nan\n",
                "year1996b[\"CASIAM\"] = np.nan\n",
                "year1996b[\"CASIAW\"] = np.nan\n",
                "year1996b[\"CNHPIT\"] = np.nan\n",
                "year1996b[\"CNHPIM\"] = np.nan\n",
                "year1996b[\"CNHPIW\"] = np.nan\n",
                "\n",
                "\n",
                "\n",
                "\n",
                "#and just to make sure everything worked....\n",
                "print(year1996b.columns)\n",
                "\n",
                "# 6. Check for missing values\n",
                "oldest = [year1996b, year1997b, year1998b, year1999b, year2000b, year2001b, year2002b, year2003b, year2004b, year2005b, year2006b, year2007b]\n",
                "for year in oldest:\n",
                "    print(year[['UNITID', 'CIPCODE', 'CTOTALT', 'CTOTALM', 'CTOTALW', 'CAIANT', 'CAIANM', 'CAIANW', 'CASIAT', 'CASIAM', 'CASIAW', 'CBKAAT',\n",
                "   'CBKAAM', 'CBKAAW', 'CHISPT', 'CHISPM', 'CHISPW', 'CNHPIT', 'CNHPIM', 'CNHPIW', 'CWHITT', 'CWHITM', 'CWHITW', 'year']].isna().sum())\n",
                "###### The only missing values are those for Asian and HPI, which is correct!\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 31,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "(68646, 24)\n",
                        "(67578, 24)\n",
                        "(66018, 24)\n",
                        "(63905, 24)\n",
                        "(62059, 24)\n",
                        "(60267, 24)\n",
                        "(59959, 24)\n",
                        "(58189, 24)\n",
                        "(52525, 24)\n",
                        "(58298, 24)\n",
                        "(53460, 24)\n",
                        "(53191, 24)\n"
                    ]
                }
            ],
            "source": [
                "#Again checking to see how many rows and columns were in each dataframe after that step so that I can track changes in the datasets across this cleaning/manipulation process:\n",
                "print(year2007b.shape)\n",
                "print(year2006b.shape)\n",
                "print(year2005b.shape)\n",
                "print(year2004b.shape)\n",
                "print(year2003b.shape)\n",
                "print(year2002b.shape)\n",
                "print(year2001b.shape)\n",
                "print(year2000b.shape)\n",
                "print(year1999b.shape)\n",
                "print(year1998b.shape)\n",
                "print(year1997b.shape)\n",
                "print(year1996b.shape)\n",
                "\n",
                "#and we have the same # of rows as before, but 24 columns as desired.\n",
                "#2007\t(68646, 24)\n",
                "#2006\t(67578, 24)\n",
                "#2005\t(66018, 24)\n",
                "#2004\t(63905, 24)\n",
                "#2003\t(62059, 24)\n",
                "#2002\t(60267, 24)\n",
                "#2001\t(59959, 24)\n",
                "#2000\t(58189, 24)\n",
                "#1999\t(52525, 24)\n",
                "#1998\t(58298, 24)\n",
                "#1997\t(53460, 24)\n",
                "#1996\t(53191, 24)"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "# Part 3: Merge All Datasets\n",
                "I now know that I have 29 datasets (1996-2024), all with the same columns and no missing values except for the values missing because the data from racial categories including Asian/Native Hawaiian/Pacific Islanders were not recorded in a consistent way. Therefore, I will use pd.concat to merge them."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 32,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "Index(['UNITID', 'CIPCODE', 'CTOTALM', 'CTOTALW', 'CAIANM', 'CAIANW', 'CBKAAM',\n",
                        "       'CBKAAW', 'CHISPM', 'CHISPW', 'CWHITM', 'CWHITW', 'year', 'CTOTALT',\n",
                        "       'CAIANT', 'CBKAAT', 'CHISPT', 'CWHITT', 'CASIAT', 'CASIAM', 'CASIAW',\n",
                        "       'CNHPIT', 'CNHPIM', 'CNHPIW'],\n",
                        "      dtype='object')\n",
                        "<class 'pandas.core.frame.DataFrame'>\n",
                        "Index: 2072306 entries, 57 to 307656\n",
                        "Data columns (total 24 columns):\n",
                        " #   Column   Dtype  \n",
                        "---  ------   -----  \n",
                        " 0   UNITID   int64  \n",
                        " 1   CIPCODE  float64\n",
                        " 2   CTOTALM  int64  \n",
                        " 3   CTOTALW  int64  \n",
                        " 4   CAIANM   int64  \n",
                        " 5   CAIANW   int64  \n",
                        " 6   CBKAAM   int64  \n",
                        " 7   CBKAAW   int64  \n",
                        " 8   CHISPM   int64  \n",
                        " 9   CHISPW   int64  \n",
                        " 10  CWHITM   int64  \n",
                        " 11  CWHITW   int64  \n",
                        " 12  year     int64  \n",
                        " 13  CTOTALT  int64  \n",
                        " 14  CAIANT   int64  \n",
                        " 15  CBKAAT   int64  \n",
                        " 16  CHISPT   int64  \n",
                        " 17  CWHITT   int64  \n",
                        " 18  CASIAT   float64\n",
                        " 19  CASIAM   float64\n",
                        " 20  CASIAW   float64\n",
                        " 21  CNHPIT   float64\n",
                        " 22  CNHPIM   float64\n",
                        " 23  CNHPIW   float64\n",
                        "dtypes: float64(7), int64(17)\n",
                        "memory usage: 395.3 MB\n",
                        "(2072306, 24)\n"
                    ]
                }
            ],
            "source": [
                "#  Merge datasets using pd.concat\n",
                "\n",
                "combined_df = pd.concat([year1996b, year1997b, year1998b, year1999b, year2000b, year2001b, year2002b, year2003b, year2004b, year2005b, year2006b, year2007b, year2008b, year2009b,\n",
                "                          year2010b, year2011b, year2012b, year2013b, year2014b, year2015b, year2016b, year2017b, year2018b, year2019b, year2020b, year2021b, year2022b, year2023b, \n",
                "                          year2024b], axis=0)\n",
                "\n",
                "#To see whether it worked\n",
                "print(combined_df.columns)\n",
                "combined_df.head()\n",
                "combined_df.info()\n",
                "print(combined_df.shape)\n",
                "\n",
                "# Note that the resulting combined dataframe has 24 columns and 2,072,306 rows, which is the sum of the # of rows in all the dataframe \"b\"s."
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "azdata_cell_guid": "e172475a-c4ee-414a-8367-9965355dbba6"
            },
            "source": [
                "# Part 4: Deal with Data Issues\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "## Missing Data\n",
                "\n",
                "Test your dataset for missing data and handle it as needed. Make notes in the form of code comments as to your thought process."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 33,
            "metadata": {
                "azdata_cell_guid": "e1dc66ef-e471-4c27-92e7-ee878c106eba"
            },
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "UNITID          0\n",
                        "CIPCODE         0\n",
                        "CTOTALT         0\n",
                        "CTOTALM         0\n",
                        "CTOTALW         0\n",
                        "CAIANT          0\n",
                        "CAIANM          0\n",
                        "CAIANW          0\n",
                        "CASIAT     939202\n",
                        "CASIAM     939202\n",
                        "CASIAW     939202\n",
                        "CBKAAT          0\n",
                        "CBKAAM          0\n",
                        "CBKAAW          0\n",
                        "CHISPT          0\n",
                        "CHISPM          0\n",
                        "CHISPW          0\n",
                        "CNHPIT     939202\n",
                        "CNHPIM     939202\n",
                        "CNHPIW     939202\n",
                        "CWHITT          0\n",
                        "CWHITM          0\n",
                        "CWHITW          0\n",
                        "year            0\n",
                        "dtype: int64\n"
                    ]
                }
            ],
            "source": [
                "# I tested for missing data in each of the 3 subsets of the data above, but I will check here for the combined dataset:\n",
                "print(combined_df[['UNITID', 'CIPCODE', 'CTOTALT', 'CTOTALM', 'CTOTALW', 'CAIANT', 'CAIANM', 'CAIANW', 'CASIAT', 'CASIAM', 'CASIAW', 'CBKAAT',\n",
                "   'CBKAAM', 'CBKAAW', 'CHISPT', 'CHISPM', 'CHISPW', 'CNHPIT', 'CNHPIM', 'CNHPIW', 'CWHITT', 'CWHITM', 'CWHITW', 'year']].isna().sum())\n",
                "\n",
                "#Everything looks great--only missing values for Asian and HPI students!!"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "azdata_cell_guid": "1233f543-e9a0-4f78-96f5-d7536554102e"
            },
            "source": [
                "## Irregular Data \n",
                "\n",
                "Detect outliers in your dataset and handle them as needed. Use code comments to make notes about your thought process."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "azdata_cell_guid": "efed50ae-16f0-471d-98e2-632553a74c12"
            },
            "outputs": [],
            "source": [
                "#I am not particularly concerned about high \"outliers\", as these data are going to be highly skewed and I don't want to eliminate high #s (large # of graduates)\n",
                "# at this time. I may need to do some manipulation to get rid of low outliers (0s), but I would need to do that AFTER I eliminate duplicate rows if there are any.\n",
                "\n",
                "#Also, I saw above that the \"Asian\" and \"HPI\" data types are float. I tried to fix them, but it turns out that you can't turn them to int64 if the column contains NaN values, so I'll leave them.\n",
                "\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "azdata_cell_guid": "6f5b8ee0-bab3-44bc-958a-67d1e4c0407f"
            },
            "source": [
                "## Unnecessary Data\n",
                "\n",
                "Look for the different types of unnecessary data in your dataset and address it as needed. Make sure to use code comments to illustrate your thought process."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "azdata_cell_guid": "e788a239-2fbf-41de-9bd3-19e52e3b187c"
            },
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "0\n"
                    ]
                }
            ],
            "source": [
                "# I previously presumed these datasets were very clean, but was wrong (e.g., I needed to strip and capitalize column names!). This was a good reminder that one\n",
                "# should always run all steps of cleaning their data! Therefore, I wanted to take a look at any duplicate rows:\n",
                "\n",
                "#Recall that there were 2,297,863 rows in the dataset. Let's see if there are any duplicated rows:\n",
                "\n",
                "print(combined_df.duplicated().sum())\n",
                "#  There are NO duplicated rows, so none to remove!\n",
                "\n",
                "\n",
                "#I dropped unnecessary columns earlier in my process to reduce the amount of data I had"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 34,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "UNITID_CIP2DIG\n",
                            "169798.13    810\n",
                            "172699.13    746\n",
                            "217420.13    723\n",
                            "181464.13    701\n",
                            "169248.13    680\n",
                            "            ... \n",
                            "498623.52      1\n",
                            "498623.50      1\n",
                            "498623.42      1\n",
                            "498623.39      1\n",
                            "498623.13      1\n",
                            "Name: count, Length: 47822, dtype: int64"
                        ]
                    },
                    "execution_count": 34,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "#It is important to remember that each row consists of a UNITID-CIPCODE combination, with institution representing a college/university (the\n",
                "# code-name pairs can be found elsewhere), and CIPCODE representing a particular academic major code. There are 1608 unique CIPCODE values in the 2024 dataset. In 2000, \n",
                "# they began using 6-digit (instead of 2-digit) CIP codes. I believe 2-digit codes to be a sufficient level of detail for my analyses, so I will need to use slicing\n",
                "# to remove all but the first two digits. Of note is that a value of \"99\" in the CIPCODE column represents the Grand Total across all CIPCODEs.\n",
                "   \n",
                "#----------------------CHANGING TO 2-DIGIT CIP CODES AND THEN CREATING A NEW UNITID_CIPCODE SERIES/COLUMN-----------------------\n",
                "# \n",
                "# There are currently a LOT of 0s in the dataset, as there are LOTS of institutions that report 0 students graduating with many of the CIPCODES (majors). I need to \n",
                "# strip the CIPCODEs to 2-digits (broad majors, of which there are approximately 50), and then merge all of the stats from the same 2-digit CIPCODE \n",
                "# together so that I have one line for each institution for each of the 2-digit CIPCODEs. This will eliminate some of the 0 values, although not all, as not all \n",
                "# institutions will offer a degree in all CIPCODE majors. \n",
                "\n",
                "combined_df[\"CIPCODE\"].value_counts()\n",
                "\n",
                "combined_df[\"CIPCODE_2DIG\"] = combined_df[\"CIPCODE\"].astype(str).str[:2]\n",
                "combined_df[\"CIPCODE_2DIG\"].value_counts()\n",
                "\n",
                "\n",
                "#that worked, except that for values < 10, it kept the single digit plus a decimal point as the CIPCODE. Therefore, I need to have it remove the decimal points, which I'm going to do with a dictionary:\n",
                "combined_df[\"CIPCODE_2DIG\"] = combined_df[\"CIPCODE_2DIG\"].replace(\n",
                "    {\"1.\": \"01\",\n",
                "    \"2.\": \"02\",\n",
                "    \"3.\": \"03\",\n",
                "    \"4.\": \"04\",\n",
                "    \"5.\": \"05\",\n",
                "    \"6.\": \"06\",\n",
                "    \"7.\": \"07\",\n",
                "    \"8.\": \"08\",\n",
                "    \"9.\": \"09\"}\n",
                ")\n",
                "combined_df[\"CIPCODE_2DIG\"].value_counts(ascending=True, dropna=False)\n",
                "\n",
                "# and my value_counts tell me that it worked!! But note that the interpretation here can be tricky.....each university will still be represented across multiple rows. But now there might be several of those\n",
                "# rows with the same CIPCODE because they might have previously had 10 rows with CIPCODEs of 52.xxx, which were all variants of a business degree but with slightly different foci. Now they all just have\n",
                "# the CIPCODE of 52.\n",
                "# \n",
                "# As a last step before starting some plotting, I want to collapse all rows with the same UNITID and CIPCODE into one row, so that there will be only one row per UNITID-2DIG_CIPCODE combination. One way\n",
                "# I can figure to do this is to create a new series that is a combination of the UNITID and CIPCODE, and then groupby this variable and aggregate (sum) the rest of the columns. Before I do this, I need\n",
                "# to make sure all of the columns I want to sum are integer/numeric variables.\n",
                "\n",
                "combined_df[\"UNITID_CIP2DIG\"] = combined_df[\"UNITID\"].astype(str) + \".\" + combined_df[\"CIPCODE_2DIG\"].astype(str)\n",
                "combined_df[\"UNITID_CIP2DIG\"].value_counts()\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 35,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": [
                        "(2072306, 26)\n"
                    ]
                }
            ],
            "source": [
                "#to make sure new columns were added and populated\n",
                "print(combined_df.shape)\n",
                "#2 new columns added, so all good!"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 36,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": [
                            "UNITID\n",
                            "102553    29\n",
                            "102377    29\n",
                            "102368    29\n",
                            "110608    29\n",
                            "110592    29\n",
                            "          ..\n",
                            "203881     1\n",
                            "206446     1\n",
                            "498623     1\n",
                            "499671     1\n",
                            "499811     1\n",
                            "Name: count, Length: 6622, dtype: int64"
                        ]
                    },
                    "execution_count": 36,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "\n",
                "#----------------------CREATING A NEW DATAFRAME THAT IS ONLY THE TOTAL NUMBER OF DEGREES PER UNIVERSITY ACROSS ALL CIPCODES-----------------------\n",
                "\n",
                "# A CIPCODE of 99 indicates that the row contains the values for ALL CIPCODES (i.e., all graduates across all majors) for that university, for that year. \n",
                "# I'd like a separate dataframe that contains only these rows.\n",
                "df_ttl_degrees = combined_df[combined_df[\"CIPCODE_2DIG\"]==\"99\"]\n",
                "df_ttl_degrees.head()\n",
                "df_ttl_degrees.shape[0]\n",
                "df_ttl_degrees[\"UNITID\"].value_counts()\n",
                "\n",
                "#DATASET DESCRIPTION: In this dataset, there should be one row for each UNITID-year pair, with the values in the columns representing ALL baacalaureate graduates of that year and university, regardless of \n",
                "# major (organized by racial group). Because there are 29 years of data, the highest number of times a university could be represented in this dataset is 29, and the lowest is 1. \n",
                "\n",
                "\n"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 37,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/html": [
                            "<div>\n",
                            "<style scoped>\n",
                            "    .dataframe tbody tr th:only-of-type {\n",
                            "        vertical-align: middle;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe tbody tr th {\n",
                            "        vertical-align: top;\n",
                            "    }\n",
                            "\n",
                            "    .dataframe thead th {\n",
                            "        text-align: right;\n",
                            "    }\n",
                            "</style>\n",
                            "<table border=\"1\" class=\"dataframe\">\n",
                            "  <thead>\n",
                            "    <tr style=\"text-align: right;\">\n",
                            "      <th></th>\n",
                            "      <th>UNITID</th>\n",
                            "      <th>CIPCODE_2DIG</th>\n",
                            "      <th>year</th>\n",
                            "      <th>CTOTALM</th>\n",
                            "      <th>CTOTALW</th>\n",
                            "      <th>CAIANM</th>\n",
                            "      <th>CAIANW</th>\n",
                            "      <th>CBKAAM</th>\n",
                            "      <th>CBKAAW</th>\n",
                            "      <th>CHISPM</th>\n",
                            "      <th>...</th>\n",
                            "      <th>CAIANT</th>\n",
                            "      <th>CBKAAT</th>\n",
                            "      <th>CHISPT</th>\n",
                            "      <th>CWHITT</th>\n",
                            "      <th>CASIAT</th>\n",
                            "      <th>CASIAM</th>\n",
                            "      <th>CASIAW</th>\n",
                            "      <th>CNHPIT</th>\n",
                            "      <th>CNHPIM</th>\n",
                            "      <th>CNHPIW</th>\n",
                            "    </tr>\n",
                            "  </thead>\n",
                            "  <tbody>\n",
                            "    <tr>\n",
                            "      <th>0</th>\n",
                            "      <td>100654</td>\n",
                            "      <td>01</td>\n",
                            "      <td>1996</td>\n",
                            "      <td>3</td>\n",
                            "      <td>1</td>\n",
                            "      <td>0</td>\n",
                            "      <td>0</td>\n",
                            "      <td>1</td>\n",
                            "      <td>1</td>\n",
                            "      <td>0</td>\n",
                            "      <td>...</td>\n",
                            "      <td>0</td>\n",
                            "      <td>2</td>\n",
                            "      <td>0</td>\n",
                            "      <td>0</td>\n",
                            "      <td>0.0</td>\n",
                            "      <td>0.0</td>\n",
                            "      <td>0.0</td>\n",
                            "      <td>0.0</td>\n",
                            "      <td>0.0</td>\n",
                            "      <td>0.0</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>1</th>\n",
                            "      <td>100654</td>\n",
                            "      <td>01</td>\n",
                            "      <td>1997</td>\n",
                            "      <td>5</td>\n",
                            "      <td>3</td>\n",
                            "      <td>0</td>\n",
                            "      <td>0</td>\n",
                            "      <td>5</td>\n",
                            "      <td>3</td>\n",
                            "      <td>0</td>\n",
                            "      <td>...</td>\n",
                            "      <td>0</td>\n",
                            "      <td>8</td>\n",
                            "      <td>0</td>\n",
                            "      <td>0</td>\n",
                            "      <td>0.0</td>\n",
                            "      <td>0.0</td>\n",
                            "      <td>0.0</td>\n",
                            "      <td>0.0</td>\n",
                            "      <td>0.0</td>\n",
                            "      <td>0.0</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>2</th>\n",
                            "      <td>100654</td>\n",
                            "      <td>01</td>\n",
                            "      <td>1998</td>\n",
                            "      <td>2</td>\n",
                            "      <td>0</td>\n",
                            "      <td>0</td>\n",
                            "      <td>0</td>\n",
                            "      <td>2</td>\n",
                            "      <td>0</td>\n",
                            "      <td>0</td>\n",
                            "      <td>...</td>\n",
                            "      <td>0</td>\n",
                            "      <td>2</td>\n",
                            "      <td>0</td>\n",
                            "      <td>0</td>\n",
                            "      <td>0.0</td>\n",
                            "      <td>0.0</td>\n",
                            "      <td>0.0</td>\n",
                            "      <td>0.0</td>\n",
                            "      <td>0.0</td>\n",
                            "      <td>0.0</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>3</th>\n",
                            "      <td>100654</td>\n",
                            "      <td>01</td>\n",
                            "      <td>1999</td>\n",
                            "      <td>5</td>\n",
                            "      <td>0</td>\n",
                            "      <td>0</td>\n",
                            "      <td>0</td>\n",
                            "      <td>5</td>\n",
                            "      <td>0</td>\n",
                            "      <td>0</td>\n",
                            "      <td>...</td>\n",
                            "      <td>0</td>\n",
                            "      <td>5</td>\n",
                            "      <td>0</td>\n",
                            "      <td>0</td>\n",
                            "      <td>0.0</td>\n",
                            "      <td>0.0</td>\n",
                            "      <td>0.0</td>\n",
                            "      <td>0.0</td>\n",
                            "      <td>0.0</td>\n",
                            "      <td>0.0</td>\n",
                            "    </tr>\n",
                            "    <tr>\n",
                            "      <th>4</th>\n",
                            "      <td>100654</td>\n",
                            "      <td>01</td>\n",
                            "      <td>2001</td>\n",
                            "      <td>1</td>\n",
                            "      <td>1</td>\n",
                            "      <td>0</td>\n",
                            "      <td>0</td>\n",
                            "      <td>1</td>\n",
                            "      <td>1</td>\n",
                            "      <td>0</td>\n",
                            "      <td>...</td>\n",
                            "      <td>0</td>\n",
                            "      <td>2</td>\n",
                            "      <td>0</td>\n",
                            "      <td>0</td>\n",
                            "      <td>0.0</td>\n",
                            "      <td>0.0</td>\n",
                            "      <td>0.0</td>\n",
                            "      <td>0.0</td>\n",
                            "      <td>0.0</td>\n",
                            "      <td>0.0</td>\n",
                            "    </tr>\n",
                            "  </tbody>\n",
                            "</table>\n",
                            "<p>5 rows × 24 columns</p>\n",
                            "</div>"
                        ],
                        "text/plain": [
                            "   UNITID CIPCODE_2DIG  year  CTOTALM  CTOTALW  CAIANM  CAIANW  CBKAAM  \\\n",
                            "0  100654           01  1996        3        1       0       0       1   \n",
                            "1  100654           01  1997        5        3       0       0       5   \n",
                            "2  100654           01  1998        2        0       0       0       2   \n",
                            "3  100654           01  1999        5        0       0       0       5   \n",
                            "4  100654           01  2001        1        1       0       0       1   \n",
                            "\n",
                            "   CBKAAW  CHISPM  ...  CAIANT  CBKAAT  CHISPT  CWHITT  CASIAT  CASIAM  \\\n",
                            "0       1       0  ...       0       2       0       0     0.0     0.0   \n",
                            "1       3       0  ...       0       8       0       0     0.0     0.0   \n",
                            "2       0       0  ...       0       2       0       0     0.0     0.0   \n",
                            "3       0       0  ...       0       5       0       0     0.0     0.0   \n",
                            "4       1       0  ...       0       2       0       0     0.0     0.0   \n",
                            "\n",
                            "   CASIAW  CNHPIT  CNHPIM  CNHPIW  \n",
                            "0     0.0     0.0     0.0     0.0  \n",
                            "1     0.0     0.0     0.0     0.0  \n",
                            "2     0.0     0.0     0.0     0.0  \n",
                            "3     0.0     0.0     0.0     0.0  \n",
                            "4     0.0     0.0     0.0     0.0  \n",
                            "\n",
                            "[5 rows x 24 columns]"
                        ]
                    },
                    "execution_count": 37,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": [
                "\n",
                "#----------------------CREATING A NEW DATAFRAME THAT IS ALL BUT THE TOTAL (I.E., THAT CONTAINS UNIQUE CIPCODE-UNITID-year PAIRS) -----------------------\n",
                "\n",
                "df_allmajors = combined_df[combined_df[\"CIPCODE_2DIG\"] != \"99\"]\n",
                "\n",
                "df_allmajors_totalled = df_allmajors.groupby([\"UNITID\",\"CIPCODE_2DIG\", \"year\"]).sum().reset_index()\n",
                "#get rid of the 6 digit cipcode and the one that's a combination of unit and 2-digit cipcode (no longer needed)\n",
                "df_allmajors_totalled = df_allmajors_totalled.drop([\"CIPCODE\", \"UNITID_CIP2DIG\"], axis=1)\n",
                "df_allmajors_totalled.head()\n",
                "\n",
                "# In this dataset, there should be one row for each UNITID-year-CIPCODE combination, with the values in the columns representing baacalaureate graduates in\n",
                "# that year, 2-digit major, and university (organized by racial group). Because there are often MANY rows for a single year, 2-digit major, and university combination. Thus, I needed to aggregate by 2-digit\n",
                "# CIPCODE.\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "azdata_cell_guid": "53e0cf94-c68a-4fa0-9849-9505a66bcce6"
            },
            "source": [
                "## Inconsistent Data\n",
                "\n",
                "Check for inconsistent data and address any that arises. As always, use code comments to illustrate your thought process."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "azdata_cell_guid": "e9de6624-812a-43f8-8e20-93b4a49b091f"
            },
            "outputs": [],
            "source": [
                "# I'm not sure exactly what should go in this section, but I think I've addressed all of the issues with the datasets above. The classification/coding of Asian and HPI students was an inconsistency addressed\n",
                "# above.\n"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {
                "azdata_cell_guid": "dedc0bfe-17d0-40b2-914f-2ddb54f9ce0d"
            },
            "source": [
                "## Summarize Your Results\n",
                "\n",
                "Make note of your answers to the following questions.\n",
                "\n",
                "1. Did you find all four types of dirty data in your dataset?\n",
                "2. Did the process of cleaning your data give you new insights into your dataset?\n",
                "3. Is there anything you would like to make note of when it comes to manipulating the data and making visualizations?"
            ]
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": [
                "1. DID YOU FIND ALL FOUR TYPES OF DIRTY DATA IN YOUR DATASET?\n",
                "I was really surprised to find \"strip\" errors in the names of the variables in this dataset. Because it's based on a huge, federally-funded, publicly-available dataset, I thought for sure the data would be really clean. But when I was first trying to merge by column name I kept running into issues because of a space before the column names in some of the years' datasets. It was a good reminder to always \"strip\", even when you don't anticipate there being any issues. Similarly, I was surprised that the capitalization of the variable names changed across years, again leading to issues when I tried to merge.  I did NOT find any missing data, but I didn't expect to since these datasets had values already imputed. As far as outliers, I didn't want to eliminate any outliers at this time (before visualizing) because I already expect these data to be highly skewed, and I don't like to eliminate outliers without a clear rationale and cutoff.  There were some inconsistencies in how \"Asian\" and \"Native Hawaiian/Asian Pacific Islanders\" were recorded in the data, so I chose to include these categories separately starting in the year in which they first began recording them as such. \n",
                "\n",
                "2. DID THE PROCESS OF CLEANING YOUR DATA GIVE YOU NEW INSIGHTS INTO YOUR DATASET?\n",
                "It definitely gave me headaches ;). It did, however, give me insight into the scope of the datsets, the nature of the CIPCODE variable and its use, and how many steps it takes to simply manipulate a dataset of this size into what I wanted for analysis. This process also really hammered home the importance of running really basic stats on your dataset every time you make a change (I ran \"shape\") to keep an eye on what each manipulation is doing to the dataset. I was able to catch errors by doing so (of course, I only started doing so because I found errors I had made!).\n",
                "\n",
                "3. IS THERE ANYTHING YOU WOULD LIKE TO MAKE NOTE OF WHEN IT COMES TO MANIPULATING THE DATA AND MAKING VISUALIZATIONS?\n",
                "One thing I want to keep an eye on is low outliers. For example, when I ran value counts on CTOTALT, which is the total # of degrees conferred across demographic groups in a single year-CIP-university combination, there were a fair number of \"1\" values. This not only seems suspicious, but also those low outliers could pull down my means and muddy interpretation. So I *may* need to set a somewhat arbitrary cutoff of \"minimum number of graduates\" needed for an institution-CIP-year combo to be included in the dataset. Similarly, I'll need to think about whether it makes any sense to look at the *proportion* of graduates in each racial/ethnic category (and gender) instead of just the raw #s. We'll see.\n",
                "\n",
                "\n",
                "\n",
                "DATASETS TO BE SAVED FOR USE IN VISUALIZATION AND GOING FORWARD:\n",
                "1. df_ttl_degrees: This dataset has 72,989 rows of data, with each row representing a university-year combination for TOTAL degrees conferred (CIPCODE=99). Thus, there are up to 29 rows for each university (i.e., 29 years). There are 26 columns, with the most important ones representing the #s of students who received Bachelors' degrees by demographic group. This dataset will allow me to look at demographic changes in the # of degrees conferred over time REGARDLESS of major (i.e., collapsed across major).\n",
                "\n",
                "2. df_all_majors_totalled: This dataset has 808,853 rows of data, with each row representing a university-year-2digitCIP combination. This dataset will allow me to look at changes in the # of degrees conferred over time, by major and demographic group. Of note, taking this dataset and aggregating by 2digitCIP *should* yield the same dataset as df_ttl_degrees. But because the information was presented in this way already, I chose to save the datasets separately."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": 40,
            "metadata": {},
            "outputs": [],
            "source": [
                "df_ttl_degrees.to_csv('univ_year_ttldegrees.csv', index=False)\n",
                "df_allmajors_totalled.to_csv('univ_year_CIP.csv', index=False)"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.13.9"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 2
}
